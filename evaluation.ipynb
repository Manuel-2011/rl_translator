{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffda8ffc",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e904aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, spa_path, wayuu_path):\n",
    "        with open(spa_path, 'r', encoding='utf-8') as f:\n",
    "            self.spa_lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "        with open(wayuu_path, 'r', encoding='utf-8') as f:\n",
    "            self.wayuu_lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.spa_lines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spa = self.spa_lines[idx]\n",
    "        wayuu = self.wayuu_lines[idx]\n",
    "        \n",
    "        return spa, wayuu\n",
    "    \n",
    "spanish_val_file = 'datasets/dev.es.txt'\n",
    "wayuu_val_file = 'datasets/dev.guc.txt'\n",
    "\n",
    "# Load the dataset\n",
    "dataset = TextDataset(spanish_val_file, wayuu_val_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d81292",
   "metadata": {},
   "source": [
    "### Eval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf39269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/projects/rl_translator/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-09 20:27:27,712\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sacrebleu\n",
    "from tqdm import tqdm\n",
    "from vllm import SamplingParams\n",
    "\n",
    "def get_rewards_translation(generations, correct_translations):\n",
    "\n",
    "    bleu = sacrebleu.BLEU(effective_order = True)\n",
    "    def get_bleu_score(sample, correct_translation):\n",
    "        # Compute bleu score for each sample. \n",
    "        # Bleu score normalized to [0, 1]\n",
    "        return bleu.sentence_score(sample, \n",
    "                                   [correct_translation]\n",
    "                                   ).score\n",
    "\n",
    "    answer_bleu_scores = [\n",
    "        get_bleu_score(sample, translation)\n",
    "        for sample, translation in zip(generations, correct_translations)\n",
    "    ]\n",
    "    \n",
    "    return answer_bleu_scores\n",
    "\n",
    "translate_prompt_template_tool=\"\"\"Translate the following Spanish text into Wayuunaiki.\n",
    "Begin by identifying any words or phrases you're unsure how to translate. Then, you may look up those words using the dictionary tool by wrapping the Spanish word in <spa_to_wayuu> and </spa_to_wayuu>,\n",
    "and doind that for every unknown word. The dictionary will return matches enclosed in <matches> and </matches>. You can use the dictionary as many times as necessary.\n",
    "Once you have all the information you need, provide the final translation enclosed in <answer> and </answer>. For example: <answer> xxx </answer>.\n",
    "\n",
    "Spanish text: {}\"\"\"\n",
    "def generate_batch_completion(model, tokenizer, prompts: list, actions_num=1, **kwargs):\n",
    "    batch = [[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": translate_prompt_template_tool.format(prompt)}\n",
    "    ] for prompt in prompts]\n",
    "    texts = tokenizer.apply_chat_template(\n",
    "        batch,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    default_sampling_args = {\n",
    "        'max_new_tokens': 512,\n",
    "        'temperature': 0.8,\n",
    "        'top_p': 0.95,\n",
    "    }\n",
    "    default_sampling_args.update(kwargs)\n",
    "\n",
    "    model_inputs = tokenizer(texts, padding='longest', padding_side='left')\n",
    "\n",
    "    inputs = model_inputs.input_ids\n",
    "    dones = [False] * len(prompts)\n",
    "    prompt_length = [len(input_ids) for input_ids in inputs]\n",
    "    mask = [[1] * len(input_ids) for input_ids in inputs]\n",
    "    responses = [\"\"] * len(prompts)\n",
    "    tools_enabled = kwargs.get('tools', [])\n",
    "    stop_tokens = [tool['end_token'] for tool in tools_enabled]\n",
    "    tool_used = [False] * len(prompts)\n",
    "    how_many_tool_calls = [0] * len(prompts)\n",
    "    for action_step in range(actions_num + 1 if len(tools_enabled) > 0 else 1):\n",
    "        sampling_params = SamplingParams(temperature=default_sampling_args[\"temperature\"], top_p=default_sampling_args['top_p'], top_k=-1, max_tokens=default_sampling_args['max_new_tokens'],\n",
    "            stop=stop_tokens)\n",
    "        outputs = model.generate(prompt_token_ids=inputs, sampling_params=sampling_params, lora_request=kwargs['lora_request'])\n",
    "\n",
    "        for j, output in enumerate(outputs):\n",
    "            if dones[j]:\n",
    "                continue\n",
    "            \n",
    "            for tool in tools_enabled:\n",
    "                if output.outputs[0].stop_reason == tool['end_token'] and tool['start_token'] in output.outputs[0].text:\n",
    "                    api_args = output.outputs[0].text.split(tool['start_token'])[1].strip()\n",
    "                    api_result = tool['api'](api_args)\n",
    "                    responses[j] += f\"{tool['start_token']} \" + api_args + f\" {tool['end_token']}\" + api_result\n",
    "                    api_result_tokens = tokenizer.encode(api_result, return_tensors=None)\n",
    "                    inputs[j] += list(output.outputs[0].token_ids) + api_result_tokens\n",
    "\n",
    "                    tool_used[j] = True\n",
    "                    how_many_tool_calls[j] += 1\n",
    "                    break # Only one tool can be used at a time\n",
    "            if output.outputs[0].finish_reason == \"stop\" and output.outputs[0].stop_reason is None:\n",
    "                responses[j] += output.outputs[0].text\n",
    "                dones[j] = True\n",
    "            elif output.outputs[0].stop_reason not in stop_tokens:\n",
    "                # print(f\"Unexpected finish reason: {output.outputs[0].finish_reason} {output.outputs[0].stop_reason}\")\n",
    "                responses[j] += output.outputs[0].text\n",
    "\n",
    "                dones[j] = True\n",
    "\n",
    "    return responses, tool_used, how_many_tool_calls\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_answer(response, transform_fn = lambda x: x, nan_val = None)->str|None:\n",
    "    ans = re.match('.*?<answer>(.*?)</answer>\\s*$', response, re.DOTALL|re.MULTILINE)\n",
    "    if ans:\n",
    "        try:\n",
    "            return transform_fn(ans[1].strip())\n",
    "        except:\n",
    "            return nan_val\n",
    "    return nan_val\n",
    "\n",
    "def evaluate_model(model, tokenizer, dataloader, actions_num=1, lora_request=None, tools=None):\n",
    "    sum_bleu = 0\n",
    "    num_samples = 0\n",
    "    tools_used_in_total = 0\n",
    "    calls_per_sample = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            inputs, targets = batch\n",
    "\n",
    "            # Generate translations\n",
    "            outputs, tools_used, how_many_tool_calls = generate_batch_completion(model, tokenizer, inputs, actions_num=actions_num, lora_request=lora_request, tools=tools)\n",
    "\n",
    "            tools_used_in_total += sum(tools_used)\n",
    "            calls_per_sample += sum(how_many_tool_calls)\n",
    "\n",
    "            generated_translations = [\n",
    "                extract_answer(output, transform_fn=lambda x: x.strip(), nan_val='')\n",
    "                for output in outputs\n",
    "            ]\n",
    "            # Calculate BLEU scores\n",
    "            bleu_scores = get_rewards_translation(generated_translations, targets)\n",
    "            \n",
    "            sum_bleu += sum(bleu_scores)\n",
    "            num_samples += len(bleu_scores)\n",
    "    avg_bleu = sum_bleu / num_samples if num_samples > 0 else 0\n",
    "    tools_used_avg = tools_used_in_total / num_samples\n",
    "    calls_per_sample_avg = calls_per_sample / tools_used_in_total\n",
    "    return avg_bleu, tools_used_avg, calls_per_sample_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0681dd90",
   "metadata": {},
   "source": [
    "### tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a3e47b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spa_to_wayu_dictionary(spanish_word, max_matches=5):\n",
    "    dictionary_path = 'assets/spanish_to_wayuunaiki_short.csv'\n",
    "\n",
    "    with open(dictionary_path, 'r', encoding='utf-8') as f:\n",
    "        all_matches = []\n",
    "        line = f.readline()\n",
    "        while line != '' and len(all_matches) < max_matches:\n",
    "            data = line.strip().split(',')\n",
    "            if re.search(rf'\\b{re.escape(spanish_word)}\\b', data[0], re.IGNORECASE):\n",
    "                all_matches.append(data)\n",
    "            line = f.readline()\n",
    "\n",
    "    if len(all_matches) > 0:\n",
    "        result = \" <matches> \" + '\\n'.join(f'{spa}: {wayuu}' for spa, wayuu in all_matches) + \" </matches>\"\n",
    "        # print(f'CORRECT USE OF SPA_TO_WAYU TOOL. Word: {spanish_word}, Result: {result}')\n",
    "    else:\n",
    "        result = \" <matches> No matches found </matches>\"\n",
    "        # print(f'NO_MATCHES SPA_TO_WAYU TOOL. Word: {spanish_word}')\n",
    "\n",
    "    return result\n",
    "\n",
    "TOOLS = [\n",
    "    {\n",
    "        'name': 'spa_to_wayu',\n",
    "        'description': 'A tool that translates a word from Spanish to Wayuunaiki.',\n",
    "        'api': spa_to_wayu_dictionary,\n",
    "        'start_token': '<spa_to_wayuu>',\n",
    "        'end_token': '</spa_to_wayuu>',\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e573b92",
   "metadata": {},
   "source": [
    "### Model with SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7707bb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-09 20:28:52,189] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-09 20:28:55 __init__.py:207] Automatically detected platform cuda.\n",
      "INFO 05-09 20:29:02 config.py:549] This model supports multiple tasks: {'reward', 'generate', 'classify', 'embed', 'score'}. Defaulting to 'generate'.\n",
      "INFO 05-09 20:29:02 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='Qwen/Qwen2.5-0.5B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-0.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-0.5B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "WARNING 05-09 20:29:03 interface.py:304] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 05-09 20:29:03 cuda.py:229] Using Flash Attention backend.\n",
      "INFO 05-09 20:29:03 model_runner.py:1110] Starting to load model Qwen/Qwen2.5-0.5B-Instruct...\n",
      "INFO 05-09 20:29:04 weight_utils.py:254] Using model weights format ['*.safetensors']\n",
      "INFO 05-09 20:29:04 weight_utils.py:304] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.32it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-09 20:29:05 model_runner.py:1115] Loading model weights took 0.9254 GB\n",
      "INFO 05-09 20:29:05 punica_selector.py:18] Using PunicaWrapperGPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-09 20:29:06 worker.py:267] Memory profiling takes 1.01 seconds\n",
      "INFO 05-09 20:29:06 worker.py:267] the current vLLM instance can use total_gpu_memory (11.99GiB) x gpu_memory_utilization (0.20) = 2.40GiB\n",
      "INFO 05-09 20:29:06 worker.py:267] model weights take 0.93GiB; non_torch_memory takes 0.02GiB; PyTorch activation peak memory takes 1.39GiB; the rest of the memory reserved for KV Cache is 0.07GiB.\n",
      "INFO 05-09 20:29:06 executor_base.py:111] # cuda blocks: 375, # CPU blocks: 32768\n",
      "INFO 05-09 20:29:06 executor_base.py:116] Maximum concurrency for 768 tokens per request: 7.81x\n",
      "INFO 05-09 20:29:06 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:11<00:00,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-09 20:29:18 model_runner.py:1562] Graph capturing finished in 12 secs, took 0.31 GiB\n",
      "INFO 05-09 20:29:18 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 13.32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:29:18 tokenizer.py:264] No tokenizer found in models/sft_base_qwen, using base model tokenizer instead. (Exception: Unrecognized model in models/sft_base_qwen. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v3, deformable_detr, deit, depth_anything, depth_pro, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, git, glm, glm4, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mistral3, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_vl, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam_vision_model, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, textnet, time_series_transformer, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zamba2, zoedepth)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_354238/2621217833.py:111: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.\n",
      "  outputs, tools_used, how_many_tool_calls = generate_batch_completion(model, tokenizer, inputs, actions_num=actions_num, lora_request=lora_request, tools=tools)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:29:19 scheduler.py:1754] Sequence group 30 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.42it/s, est. speed input: 1616.22 toks/s, output: 1066.17 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:29:33 scheduler.py:1754] Sequence group 123 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.98it/s, est. speed input: 1231.09 toks/s, output: 1202.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.61it/s, est. speed input: 1871.90 toks/s, output: 1086.96 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.38it/s, est. speed input: 1910.52 toks/s, output: 1149.50 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:29:53 scheduler.py:1754] Sequence group 287 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.09it/s, est. speed input: 1422.36 toks/s, output: 1187.61 toks/s]\n",
      "  1%|          | 1/104 [00:44<1:15:56, 44.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:30:09 scheduler.py:1754] Sequence group 382 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.94it/s, est. speed input: 1205.12 toks/s, output: 1169.40 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.52it/s, est. speed input: 1359.84 toks/s, output: 1091.80 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:30:30 scheduler.py:1754] Sequence group 508 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.98it/s, est. speed input: 1278.16 toks/s, output: 1210.89 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.08it/s, est. speed input: 1331.15 toks/s, output: 1177.68 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:30:49 scheduler.py:1754] Sequence group 615 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.18it/s, est. speed input: 1359.99 toks/s, output: 1167.90 toks/s]\n",
      "  2%|▏         | 2/104 [01:36<1:23:34, 49.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:31:12 scheduler.py:1754] Sequence group 703 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.70it/s, est. speed input: 1121.17 toks/s, output: 1165.05 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.66it/s, est. speed input: 1113.59 toks/s, output: 1149.75 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:31:33 scheduler.py:1754] Sequence group 784 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:20<00:00,  3.19it/s, est. speed input: 976.58 toks/s, output: 1089.96 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:31:55 scheduler.py:1754] Sequence group 863 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:18<00:00,  3.42it/s, est. speed input: 1046.35 toks/s, output: 1121.44 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:32:14 scheduler.py:1754] Sequence group 927 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.76it/s, est. speed input: 1153.10 toks/s, output: 1133.22 toks/s]\n",
      "  3%|▎         | 3/104 [03:07<1:54:39, 68.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:32:30 scheduler.py:1754] Sequence group 1023 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.79it/s, est. speed input: 1662.17 toks/s, output: 1149.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.85it/s, est. speed input: 1633.88 toks/s, output: 1146.81 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:05<00:00, 11.60it/s, est. speed input: 2588.70 toks/s, output: 1008.77 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:32:49 scheduler.py:1754] Sequence group 1198 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:06<00:00,  9.74it/s, est. speed input: 2282.44 toks/s, output: 1073.01 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.92it/s, est. speed input: 1660.42 toks/s, output: 1128.84 toks/s]\n",
      "  4%|▍         | 4/104 [03:44<1:33:15, 55.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:33:06 scheduler.py:1754] Sequence group 1317 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.05it/s, est. speed input: 1191.10 toks/s, output: 1190.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.85it/s, est. speed input: 1376.38 toks/s, output: 1053.71 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:33:25 scheduler.py:1754] Sequence group 1453 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.57it/s, est. speed input: 1341.47 toks/s, output: 1038.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.24it/s, est. speed input: 1509.81 toks/s, output: 1082.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:33:43 scheduler.py:1754] Sequence group 1572 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.47it/s, est. speed input: 1352.65 toks/s, output: 1066.01 toks/s]\n",
      "  5%|▍         | 5/104 [04:33<1:27:54, 53.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:33:57 scheduler.py:1754] Sequence group 1661 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.47it/s, est. speed input: 1479.79 toks/s, output: 1088.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.53it/s, est. speed input: 1333.65 toks/s, output: 1031.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:34:12 scheduler.py:1754] Sequence group 1772 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.45it/s, est. speed input: 1382.97 toks/s, output: 1046.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.41it/s, est. speed input: 1408.42 toks/s, output: 1112.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:34:31 scheduler.py:1754] Sequence group 1885 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.44it/s, est. speed input: 1665.25 toks/s, output: 1127.17 toks/s]\n",
      "  6%|▌         | 6/104 [05:20<1:23:47, 51.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:34:46 scheduler.py:1754] Sequence group 1981 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.81it/s, est. speed input: 1015.43 toks/s, output: 1176.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:35:02 scheduler.py:1754] Sequence group 2027 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.29it/s, est. speed input: 912.57 toks/s, output: 1262.71 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.37it/s, est. speed input: 1143.91 toks/s, output: 1229.95 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:35:21 scheduler.py:1754] Sequence group 2145 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.80it/s, est. speed input: 1244.24 toks/s, output: 1187.12 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:35:36 scheduler.py:1754] Sequence group 2208 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.77it/s, est. speed input: 1237.87 toks/s, output: 1170.93 toks/s]\n",
      "  7%|▋         | 7/104 [06:23<1:28:46, 54.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:35:54 scheduler.py:1754] Sequence group 2297 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.76it/s, est. speed input: 929.50 toks/s, output: 1151.06 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:36:11 scheduler.py:1754] Sequence group 2367 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.76it/s, est. speed input: 932.71 toks/s, output: 1146.40 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:36:28 scheduler.py:1754] Sequence group 2428 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:18<00:00,  3.48it/s, est. speed input: 868.18 toks/s, output: 1146.12 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:36:46 scheduler.py:1754] Sequence group 2480 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:21<00:00,  3.04it/s, est. speed input: 762.84 toks/s, output: 1152.49 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:37:05 scheduler.py:1754] Sequence group 2545 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:15<00:00,  4.08it/s, est. speed input: 1027.49 toks/s, output: 1183.46 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.85it/s, est. speed input: 1062.61 toks/s, output: 1106.96 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:37:24 scheduler.py:1754] Sequence group 2649 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.39it/s, est. speed input: 1197.34 toks/s, output: 1121.03 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:37:42 scheduler.py:1754] Sequence group 2744 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.58it/s, est. speed input: 1032.38 toks/s, output: 1088.54 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:37:58 scheduler.py:1754] Sequence group 2807 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.45it/s, est. speed input: 1010.09 toks/s, output: 1178.49 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.50it/s, est. speed input: 1024.33 toks/s, output: 1198.69 toks/s]\n",
      "  9%|▊         | 9/104 [09:00<1:45:13, 66.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:38:19 scheduler.py:1754] Sequence group 2909 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.73it/s, est. speed input: 1469.29 toks/s, output: 1146.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.66it/s, est. speed input: 1744.65 toks/s, output: 1130.23 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:38:36 scheduler.py:1754] Sequence group 3041 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.63it/s, est. speed input: 1367.24 toks/s, output: 1064.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.85it/s, est. speed input: 1847.88 toks/s, output: 1102.51 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:38:54 scheduler.py:1754] Sequence group 3191 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:06<00:00,  9.90it/s, est. speed input: 2077.57 toks/s, output: 1097.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.81it/s, est. speed input: 1208.15 toks/s, output: 1208.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:39:11 scheduler.py:1754] Sequence group 3304 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.00it/s, est. speed input: 1045.11 toks/s, output: 1109.99 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:39:25 scheduler.py:1754] Sequence group 3376 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.04it/s, est. speed input: 1262.28 toks/s, output: 1140.07 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:39:40 scheduler.py:1754] Sequence group 3444 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.29it/s, est. speed input: 897.45 toks/s, output: 1175.48 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:39:55 scheduler.py:1754] Sequence group 3518 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.32it/s, est. speed input: 1111.82 toks/s, output: 1163.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.92it/s, est. speed input: 1225.78 toks/s, output: 1176.37 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:40:13 scheduler.py:1754] Sequence group 3626 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.73it/s, est. speed input: 1213.31 toks/s, output: 1181.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.53it/s, est. speed input: 1411.77 toks/s, output: 1091.36 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:40:33 scheduler.py:1754] Sequence group 3749 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.94it/s, est. speed input: 1319.93 toks/s, output: 1260.96 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:40:47 scheduler.py:1754] Sequence group 3813 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.95it/s, est. speed input: 1349.82 toks/s, output: 1136.18 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.89it/s, est. speed input: 1302.92 toks/s, output: 1041.92 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:41:04 scheduler.py:1754] Sequence group 3951 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.55it/s, est. speed input: 1706.14 toks/s, output: 1168.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.16it/s, est. speed input: 1708.24 toks/s, output: 1129.77 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.92it/s, est. speed input: 1958.60 toks/s, output: 1050.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:41:26 scheduler.py:1754] Sequence group 4122 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.81it/s, est. speed input: 1965.81 toks/s, output: 1070.06 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.66it/s, est. speed input: 1182.39 toks/s, output: 1130.23 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:41:45 scheduler.py:1754] Sequence group 4248 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.63it/s, est. speed input: 996.92 toks/s, output: 1110.67 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:41:59 scheduler.py:1754] Sequence group 4320 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.93it/s, est. speed input: 1279.24 toks/s, output: 1154.69 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:42:15 scheduler.py:1754] Sequence group 4411 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.81it/s, est. speed input: 1044.52 toks/s, output: 1147.69 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:42:30 scheduler.py:1754] Sequence group 4473 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.58it/s, est. speed input: 997.04 toks/s, output: 1137.76 toks/s]\n",
      " 13%|█▎        | 14/104 [13:17<1:23:09, 55.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:42:48 scheduler.py:1754] Sequence group 4532 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.71it/s, est. speed input: 1096.88 toks/s, output: 1148.01 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.76it/s, est. speed input: 1118.53 toks/s, output: 1141.93 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:43:12 scheduler.py:1754] Sequence group 4624 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:20<00:00,  3.08it/s, est. speed input: 920.60 toks/s, output: 1077.72 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:43:34 scheduler.py:1754] Sequence group 4687 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:20<00:00,  3.07it/s, est. speed input: 917.28 toks/s, output: 1091.87 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:43:55 scheduler.py:1754] Sequence group 4755 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.64it/s, est. speed input: 1087.89 toks/s, output: 1164.69 toks/s]\n",
      " 14%|█▍        | 15/104 [14:51<1:39:16, 66.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:44:14 scheduler.py:1754] Sequence group 4844 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.45it/s, est. speed input: 1258.07 toks/s, output: 1122.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.32it/s, est. speed input: 1264.47 toks/s, output: 1091.07 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:44:33 scheduler.py:1754] Sequence group 4986 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:06<00:00,  9.25it/s, est. speed input: 1888.41 toks/s, output: 1136.86 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.27it/s, est. speed input: 1709.82 toks/s, output: 1142.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:06<00:00,  9.43it/s, est. speed input: 1979.17 toks/s, output: 1064.60 toks/s]\n",
      " 15%|█▌        | 16/104 [15:32<1:27:05, 59.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:44:56 scheduler.py:1754] Sequence group 5152 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.05it/s, est. speed input: 1056.37 toks/s, output: 1163.93 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.88it/s, est. speed input: 1235.71 toks/s, output: 1196.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:45:16 scheduler.py:1754] Sequence group 5284 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.01it/s, est. speed input: 1269.65 toks/s, output: 1154.17 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:45:32 scheduler.py:1754] Sequence group 5370 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.71it/s, est. speed input: 1218.44 toks/s, output: 1212.29 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.23it/s, est. speed input: 1119.31 toks/s, output: 1166.79 toks/s]\n",
      " 16%|█▋        | 17/104 [16:30<1:25:27, 58.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:45:53 scheduler.py:1754] Sequence group 5476 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.25it/s, est. speed input: 1225.38 toks/s, output: 1109.72 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.36it/s, est. speed input: 1509.45 toks/s, output: 1102.14 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:46:10 scheduler.py:1754] Sequence group 5604 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.87it/s, est. speed input: 1445.27 toks/s, output: 1079.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.86it/s, est. speed input: 1491.22 toks/s, output: 1100.75 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:46:28 scheduler.py:1754] Sequence group 5740 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.81it/s, est. speed input: 1939.00 toks/s, output: 1087.77 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.16it/s, est. speed input: 1207.27 toks/s, output: 1153.08 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:46:47 scheduler.py:1754] Sequence group 5868 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.29it/s, est. speed input: 1263.79 toks/s, output: 1152.61 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.86it/s, est. speed input: 1819.06 toks/s, output: 1106.86 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:47:04 scheduler.py:1754] Sequence group 5989 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.86it/s, est. speed input: 1664.08 toks/s, output: 1143.01 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.53it/s, est. speed input: 1393.95 toks/s, output: 1073.33 toks/s]\n",
      " 18%|█▊        | 19/104 [18:02<1:13:54, 52.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:47:22 scheduler.py:1754] Sequence group 6117 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.98it/s, est. speed input: 1226.43 toks/s, output: 1196.23 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:47:37 scheduler.py:1754] Sequence group 6199 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.49it/s, est. speed input: 1342.30 toks/s, output: 1017.26 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.16it/s, est. speed input: 1283.75 toks/s, output: 1180.77 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:47:54 scheduler.py:1754] Sequence group 6304 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.45it/s, est. speed input: 1142.13 toks/s, output: 1184.43 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:48:08 scheduler.py:1754] Sequence group 6372 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.98it/s, est. speed input: 1252.56 toks/s, output: 1192.89 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:06<00:00,  9.39it/s, est. speed input: 1794.07 toks/s, output: 1139.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:48:23 scheduler.py:1754] Sequence group 6516 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  9.12it/s, est. speed input: 1846.27 toks/s, output: 1102.89 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.66it/s, est. speed input: 1397.25 toks/s, output: 1079.06 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:48:41 scheduler.py:1754] Sequence group 6643 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  7.05it/s, est. speed input: 1538.11 toks/s, output: 1084.52 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  7.03it/s, est. speed input: 1574.65 toks/s, output: 1054.19 toks/s]\n",
      " 20%|██        | 21/104 [19:37<1:08:23, 49.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:48:59 scheduler.py:1754] Sequence group 6767 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.27it/s, est. speed input: 1235.02 toks/s, output: 1115.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.67it/s, est. speed input: 1523.76 toks/s, output: 1134.79 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:49:16 scheduler.py:1754] Sequence group 6882 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.70it/s, est. speed input: 1330.90 toks/s, output: 1008.54 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:49:29 scheduler.py:1754] Sequence group 6967 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.45it/s, est. speed input: 1281.67 toks/s, output: 1041.53 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.03it/s, est. speed input: 1198.02 toks/s, output: 1187.56 toks/s]\n",
      " 21%|██        | 22/104 [20:26<1:07:15, 49.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:49:46 scheduler.py:1754] Sequence group 7080 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.25it/s, est. speed input: 1443.76 toks/s, output: 1109.01 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.32it/s, est. speed input: 1478.66 toks/s, output: 1066.80 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:50:04 scheduler.py:1754] Sequence group 7209 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.74it/s, est. speed input: 1381.98 toks/s, output: 1043.64 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:50:19 scheduler.py:1754] Sequence group 7294 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.06it/s, est. speed input: 1251.15 toks/s, output: 1163.09 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.06it/s, est. speed input: 1258.64 toks/s, output: 1146.74 toks/s]\n",
      " 22%|██▏       | 23/104 [21:14<1:06:03, 48.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:50:39 scheduler.py:1754] Sequence group 7407 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.47it/s, est. speed input: 1187.52 toks/s, output: 1132.28 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.37it/s, est. speed input: 1174.58 toks/s, output: 1159.04 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:50:58 scheduler.py:1754] Sequence group 7520 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.54it/s, est. speed input: 996.40 toks/s, output: 1131.65 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:51:13 scheduler.py:1754] Sequence group 7588 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.00it/s, est. speed input: 1097.86 toks/s, output: 1140.20 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:51:30 scheduler.py:1754] Sequence group 7668 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.47it/s, est. speed input: 980.57 toks/s, output: 1156.95 toks/s]\n",
      " 23%|██▎       | 24/104 [22:19<1:11:37, 53.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:51:45 scheduler.py:1754] Sequence group 7732 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.74it/s, est. speed input: 1171.62 toks/s, output: 1134.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:52:00 scheduler.py:1754] Sequence group 7807 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.66it/s, est. speed input: 949.80 toks/s, output: 1151.31 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.41it/s, est. speed input: 1307.61 toks/s, output: 1008.35 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:52:15 scheduler.py:1754] Sequence group 7911 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.81it/s, est. speed input: 1184.44 toks/s, output: 1168.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.41it/s, est. speed input: 1307.07 toks/s, output: 1134.68 toks/s]\n",
      " 24%|██▍       | 25/104 [23:15<1:11:36, 54.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:52:35 scheduler.py:1754] Sequence group 8019 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.61it/s, est. speed input: 1161.09 toks/s, output: 1116.80 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:52:55 scheduler.py:1754] Sequence group 8076 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:16<00:00,  3.90it/s, est. speed input: 1254.96 toks/s, output: 1146.38 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:53:18 scheduler.py:1754] Sequence group 8166 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:19<00:00,  3.29it/s, est. speed input: 1060.89 toks/s, output: 1105.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:53:39 scheduler.py:1754] Sequence group 8233 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:19<00:00,  3.30it/s, est. speed input: 1061.04 toks/s, output: 1103.31 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:54:00 scheduler.py:1754] Sequence group 8316 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:18<00:00,  3.48it/s, est. speed input: 1120.30 toks/s, output: 1105.51 toks/s]\n",
      " 25%|██▌       | 26/104 [24:46<1:25:09, 65.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:54:17 scheduler.py:1754] Sequence group 8372 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.65it/s, est. speed input: 832.95 toks/s, output: 1192.86 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:54:35 scheduler.py:1754] Sequence group 8446 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.68it/s, est. speed input: 842.65 toks/s, output: 1180.04 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.38it/s, est. speed input: 1005.86 toks/s, output: 1211.54 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:54:56 scheduler.py:1754] Sequence group 8536 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.34it/s, est. speed input: 997.19 toks/s, output: 1207.26 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:55:12 scheduler.py:1754] Sequence group 8604 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:15<00:00,  4.21it/s, est. speed input: 967.62 toks/s, output: 1150.40 toks/s]\n",
      " 26%|██▌       | 27/104 [26:06<1:29:28, 69.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:55:29 scheduler.py:1754] Sequence group 8693 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.17it/s, est. speed input: 1234.42 toks/s, output: 1120.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.59it/s, est. speed input: 1575.36 toks/s, output: 1102.39 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:55:45 scheduler.py:1754] Sequence group 8807 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.53it/s, est. speed input: 1397.90 toks/s, output: 1094.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.72it/s, est. speed input: 1474.42 toks/s, output: 1056.71 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:56:05 scheduler.py:1754] Sequence group 8932 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.49it/s, est. speed input: 1454.87 toks/s, output: 1155.49 toks/s]\n",
      " 27%|██▋       | 28/104 [26:54<1:20:14, 63.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:56:21 scheduler.py:1754] Sequence group 9023 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.75it/s, est. speed input: 1202.34 toks/s, output: 1185.17 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.72it/s, est. speed input: 1218.99 toks/s, output: 1222.39 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:56:40 scheduler.py:1754] Sequence group 9133 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.44it/s, est. speed input: 1180.55 toks/s, output: 1177.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.67it/s, est. speed input: 1246.83 toks/s, output: 1166.06 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:57:02 scheduler.py:1754] Sequence group 9257 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.14it/s, est. speed input: 1352.14 toks/s, output: 1116.94 toks/s]\n",
      " 28%|██▊       | 29/104 [27:50<1:16:24, 61.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:57:18 scheduler.py:1754] Sequence group 9335 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.38it/s, est. speed input: 981.84 toks/s, output: 1172.51 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:57:34 scheduler.py:1754] Sequence group 9403 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.53it/s, est. speed input: 1022.66 toks/s, output: 1107.53 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.44it/s, est. speed input: 1007.28 toks/s, output: 1140.89 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:57:53 scheduler.py:1754] Sequence group 9497 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.44it/s, est. speed input: 1240.35 toks/s, output: 1172.18 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:58:09 scheduler.py:1754] Sequence group 9555 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:15<00:00,  4.25it/s, est. speed input: 978.75 toks/s, output: 1153.74 toks/s]\n",
      " 29%|██▉       | 30/104 [29:00<1:18:42, 63.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:58:24 scheduler.py:1754] Sequence group 9634 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.66it/s, est. speed input: 1217.00 toks/s, output: 1152.87 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:58:39 scheduler.py:1754] Sequence group 9719 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.51it/s, est. speed input: 997.82 toks/s, output: 1151.76 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.46it/s, est. speed input: 1225.90 toks/s, output: 1208.75 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:59:00 scheduler.py:1754] Sequence group 9811 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.36it/s, est. speed input: 1208.17 toks/s, output: 1154.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.97it/s, est. speed input: 1366.36 toks/s, output: 1170.24 toks/s]\n",
      " 30%|██▉       | 31/104 [30:01<1:16:18, 62.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:59:20 scheduler.py:1754] Sequence group 9953 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.83it/s, est. speed input: 1212.17 toks/s, output: 1153.98 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:59:35 scheduler.py:1754] Sequence group 10018 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.18it/s, est. speed input: 1303.03 toks/s, output: 1156.44 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:59:49 scheduler.py:1754] Sequence group 10110 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.68it/s, est. speed input: 992.96 toks/s, output: 1120.18 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.00it/s, est. speed input: 1281.41 toks/s, output: 1218.98 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:00:07 scheduler.py:1754] Sequence group 10215 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.17it/s, est. speed input: 1328.00 toks/s, output: 1082.44 toks/s]\n",
      " 31%|███       | 32/104 [30:57<1:12:53, 60.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:00:20 scheduler.py:1754] Sequence group 10300 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.30it/s, est. speed input: 1394.37 toks/s, output: 1058.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.12it/s, est. speed input: 1204.35 toks/s, output: 1082.49 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:00:38 scheduler.py:1754] Sequence group 10411 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.39it/s, est. speed input: 1299.25 toks/s, output: 1139.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  7.02it/s, est. speed input: 1457.66 toks/s, output: 1099.39 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:00:55 scheduler.py:1754] Sequence group 10528 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.84it/s, est. speed input: 1871.86 toks/s, output: 1087.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.21it/s, est. speed input: 1272.32 toks/s, output: 1170.01 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:01:13 scheduler.py:1754] Sequence group 10655 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.44it/s, est. speed input: 1351.91 toks/s, output: 1080.06 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:01:28 scheduler.py:1754] Sequence group 10751 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.03it/s, est. speed input: 1311.96 toks/s, output: 1177.76 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.75it/s, est. speed input: 1753.20 toks/s, output: 1088.56 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:01:46 scheduler.py:1754] Sequence group 10859 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.25it/s, est. speed input: 1455.55 toks/s, output: 1182.71 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.95it/s, est. speed input: 1581.43 toks/s, output: 1128.09 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:02:02 scheduler.py:1754] Sequence group 10983 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.90it/s, est. speed input: 1206.28 toks/s, output: 1212.36 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.25it/s, est. speed input: 1314.36 toks/s, output: 1082.13 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:02:21 scheduler.py:1754] Sequence group 11103 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.87it/s, est. speed input: 1472.38 toks/s, output: 1041.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.61it/s, est. speed input: 1649.59 toks/s, output: 1116.64 toks/s]\n",
      " 34%|███▎      | 35/104 [33:19<59:55, 52.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:02:38 scheduler.py:1754] Sequence group 11227 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.39it/s, est. speed input: 1088.58 toks/s, output: 1196.19 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:02:52 scheduler.py:1754] Sequence group 11308 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.24it/s, est. speed input: 1299.07 toks/s, output: 1110.29 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:03:06 scheduler.py:1754] Sequence group 11379 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.43it/s, est. speed input: 1356.20 toks/s, output: 1133.43 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.41it/s, est. speed input: 1589.98 toks/s, output: 1138.05 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:03:23 scheduler.py:1754] Sequence group 11503 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.34it/s, est. speed input: 1359.90 toks/s, output: 1143.93 toks/s]\n",
      " 35%|███▍      | 36/104 [34:10<58:41, 51.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:03:38 scheduler.py:1754] Sequence group 11579 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.75it/s, est. speed input: 988.42 toks/s, output: 1106.85 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.48it/s, est. speed input: 1373.71 toks/s, output: 1084.24 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:03:53 scheduler.py:1754] Sequence group 11674 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.11it/s, est. speed input: 1310.26 toks/s, output: 1174.27 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:04:06 scheduler.py:1754] Sequence group 11749 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.69it/s, est. speed input: 1242.13 toks/s, output: 1244.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.51it/s, est. speed input: 1430.54 toks/s, output: 1117.06 toks/s]\n",
      " 36%|███▌      | 37/104 [35:05<58:54, 52.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:04:26 scheduler.py:1754] Sequence group 11873 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.33it/s, est. speed input: 1329.01 toks/s, output: 1098.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:04:40 scheduler.py:1754] Sequence group 11930 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.93it/s, est. speed input: 1262.50 toks/s, output: 1181.87 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:04:56 scheduler.py:1754] Sequence group 12028 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.83it/s, est. speed input: 1039.38 toks/s, output: 1180.85 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.17it/s, est. speed input: 1344.24 toks/s, output: 1206.75 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:05:15 scheduler.py:1754] Sequence group 12148 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.51it/s, est. speed input: 1209.01 toks/s, output: 1192.81 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.76it/s, est. speed input: 1197.77 toks/s, output: 1205.60 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:05:35 scheduler.py:1754] Sequence group 12263 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.04it/s, est. speed input: 1317.58 toks/s, output: 1147.38 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:05:50 scheduler.py:1754] Sequence group 12348 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.68it/s, est. speed input: 1269.65 toks/s, output: 1188.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.16it/s, est. speed input: 1412.07 toks/s, output: 1153.80 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:06:08 scheduler.py:1754] Sequence group 12468 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.45it/s, est. speed input: 1495.71 toks/s, output: 1118.01 toks/s]\n",
      " 38%|███▊      | 39/104 [36:56<58:22, 53.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:06:26 scheduler.py:1754] Sequence group 12538 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.65it/s, est. speed input: 926.98 toks/s, output: 1119.89 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:06:42 scheduler.py:1754] Sequence group 12584 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:18<00:00,  3.51it/s, est. speed input: 890.92 toks/s, output: 1118.08 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:06:58 scheduler.py:1754] Sequence group 12644 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:18<00:00,  3.44it/s, est. speed input: 874.93 toks/s, output: 1171.59 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:07:18 scheduler.py:1754] Sequence group 12714 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:19<00:00,  3.36it/s, est. speed input: 852.60 toks/s, output: 1177.72 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:07:36 scheduler.py:1754] Sequence group 12772 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:19<00:00,  3.36it/s, est. speed input: 852.50 toks/s, output: 1197.04 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.80it/s, est. speed input: 1247.49 toks/s, output: 1203.61 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:07:58 scheduler.py:1754] Sequence group 12888 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.67it/s, est. speed input: 1018.22 toks/s, output: 1109.75 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:08:13 scheduler.py:1754] Sequence group 12955 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:15<00:00,  4.14it/s, est. speed input: 909.88 toks/s, output: 1198.05 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:08:30 scheduler.py:1754] Sequence group 13018 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.90it/s, est. speed input: 1086.52 toks/s, output: 1157.71 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:08:45 scheduler.py:1754] Sequence group 13076 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.46it/s, est. speed input: 997.99 toks/s, output: 1136.29 toks/s]\n",
      " 39%|███▉      | 41/104 [39:36<1:09:28, 66.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:08:59 scheduler.py:1754] Sequence group 13170 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.42it/s, est. speed input: 1265.17 toks/s, output: 1096.08 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.51it/s, est. speed input: 1313.03 toks/s, output: 1102.13 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:09:17 scheduler.py:1754] Sequence group 13287 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.19it/s, est. speed input: 1291.65 toks/s, output: 1137.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.28it/s, est. speed input: 1789.98 toks/s, output: 1129.17 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:09:36 scheduler.py:1754] Sequence group 13418 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.62it/s, est. speed input: 1455.33 toks/s, output: 1045.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.39it/s, est. speed input: 1272.16 toks/s, output: 1086.66 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:09:53 scheduler.py:1754] Sequence group 13532 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.27it/s, est. speed input: 1073.27 toks/s, output: 1185.59 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:10:08 scheduler.py:1754] Sequence group 13612 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.56it/s, est. speed input: 1361.41 toks/s, output: 1126.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.39it/s, est. speed input: 1767.75 toks/s, output: 1150.84 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:10:25 scheduler.py:1754] Sequence group 13734 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.88it/s, est. speed input: 1461.47 toks/s, output: 1114.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.37it/s, est. speed input: 1241.60 toks/s, output: 1164.20 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:10:44 scheduler.py:1754] Sequence group 13866 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  9.10it/s, est. speed input: 1882.92 toks/s, output: 1058.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.25it/s, est. speed input: 1325.70 toks/s, output: 1184.27 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:11:02 scheduler.py:1754] Sequence group 13999 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.81it/s, est. speed input: 1699.13 toks/s, output: 1068.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.43it/s, est. speed input: 1847.00 toks/s, output: 1138.25 toks/s]\n",
      " 42%|████▏     | 44/104 [41:57<53:07, 53.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:11:23 scheduler.py:1754] Sequence group 14122 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:18<00:00,  3.52it/s, est. speed input: 867.15 toks/s, output: 1121.28 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:11:41 scheduler.py:1754] Sequence group 14198 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.42it/s, est. speed input: 1095.46 toks/s, output: 1164.98 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:12:00 scheduler.py:1754] Sequence group 14262 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.59it/s, est. speed input: 894.42 toks/s, output: 1116.79 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:12:17 scheduler.py:1754] Sequence group 14330 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:18<00:00,  3.52it/s, est. speed input: 876.26 toks/s, output: 1135.84 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:12:33 scheduler.py:1754] Sequence group 14380 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.74it/s, est. speed input: 931.36 toks/s, output: 1175.02 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.37it/s, est. speed input: 1241.59 toks/s, output: 1147.77 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:12:53 scheduler.py:1754] Sequence group 14508 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.58it/s, est. speed input: 1319.96 toks/s, output: 1103.03 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.37it/s, est. speed input: 1323.48 toks/s, output: 1172.10 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:13:12 scheduler.py:1754] Sequence group 14623 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.45it/s, est. speed input: 1581.36 toks/s, output: 1063.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.89it/s, est. speed input: 1693.11 toks/s, output: 1072.90 toks/s]\n",
      " 44%|████▍     | 46/104 [44:09<56:11, 58.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:13:30 scheduler.py:1754] Sequence group 14759 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.35it/s, est. speed input: 1250.47 toks/s, output: 1068.97 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:13:44 scheduler.py:1754] Sequence group 14842 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.54it/s, est. speed input: 1339.94 toks/s, output: 1002.42 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.34it/s, est. speed input: 1315.59 toks/s, output: 1128.34 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:14:01 scheduler.py:1754] Sequence group 14950 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.79it/s, est. speed input: 1221.14 toks/s, output: 1204.12 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.28it/s, est. speed input: 1761.70 toks/s, output: 1097.37 toks/s]\n",
      " 45%|████▌     | 47/104 [44:58<52:36, 55.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:14:19 scheduler.py:1754] Sequence group 15080 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.86it/s, est. speed input: 1207.90 toks/s, output: 1138.63 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:14:34 scheduler.py:1754] Sequence group 15139 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.20it/s, est. speed input: 1306.35 toks/s, output: 1121.72 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.54it/s, est. speed input: 1384.66 toks/s, output: 1099.55 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:14:51 scheduler.py:1754] Sequence group 15262 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.31it/s, est. speed input: 1128.07 toks/s, output: 1129.48 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:15:08 scheduler.py:1754] Sequence group 15349 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.44it/s, est. speed input: 1165.07 toks/s, output: 1211.08 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.27it/s, est. speed input: 1424.37 toks/s, output: 1126.64 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:15:26 scheduler.py:1754] Sequence group 15487 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.77it/s, est. speed input: 1583.47 toks/s, output: 1090.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.91it/s, est. speed input: 1652.89 toks/s, output: 1195.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.23it/s, est. speed input: 1780.34 toks/s, output: 1112.32 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:15:48 scheduler.py:1754] Sequence group 15652 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.33it/s, est. speed input: 1398.32 toks/s, output: 1111.34 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.63it/s, est. speed input: 1332.99 toks/s, output: 1087.10 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:16:06 scheduler.py:1754] Sequence group 15773 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.36it/s, est. speed input: 1314.36 toks/s, output: 1110.48 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:16:22 scheduler.py:1754] Sequence group 15863 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.48it/s, est. speed input: 1149.33 toks/s, output: 1181.97 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.29it/s, est. speed input: 1540.10 toks/s, output: 1093.35 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:16:39 scheduler.py:1754] Sequence group 15979 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.94it/s, est. speed input: 1272.60 toks/s, output: 1169.53 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.28it/s, est. speed input: 1255.31 toks/s, output: 1096.23 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:16:57 scheduler.py:1754] Sequence group 16090 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.74it/s, est. speed input: 1371.41 toks/s, output: 1098.56 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:17:11 scheduler.py:1754] Sequence group 16191 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.34it/s, est. speed input: 1715.03 toks/s, output: 1121.10 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.29it/s, est. speed input: 1292.94 toks/s, output: 1106.76 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:17:29 scheduler.py:1754] Sequence group 16311 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.77it/s, est. speed input: 1399.23 toks/s, output: 1023.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.05it/s, est. speed input: 1247.42 toks/s, output: 1078.24 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:17:46 scheduler.py:1754] Sequence group 16416 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.00it/s, est. speed input: 1265.42 toks/s, output: 1197.01 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:18:02 scheduler.py:1754] Sequence group 16509 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.99it/s, est. speed input: 1285.14 toks/s, output: 1130.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.01it/s, est. speed input: 1085.89 toks/s, output: 1172.16 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:18:19 scheduler.py:1754] Sequence group 16603 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.32it/s, est. speed input: 1387.02 toks/s, output: 1190.02 toks/s]\n",
      " 50%|█████     | 52/104 [49:10<44:47, 51.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:18:34 scheduler.py:1754] Sequence group 16672 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.54it/s, est. speed input: 981.01 toks/s, output: 1163.68 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:18:51 scheduler.py:1754] Sequence group 16767 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.53it/s, est. speed input: 1215.52 toks/s, output: 1220.36 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:19:04 scheduler.py:1754] Sequence group 16828 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.84it/s, est. speed input: 1065.66 toks/s, output: 1140.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.10it/s, est. speed input: 1133.10 toks/s, output: 1141.96 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:19:21 scheduler.py:1754] Sequence group 16921 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.89it/s, est. speed input: 1084.53 toks/s, output: 1121.48 toks/s]\n",
      " 51%|█████     | 53/104 [50:15<47:15, 55.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:19:36 scheduler.py:1754] Sequence group 17004 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.52it/s, est. speed input: 1362.27 toks/s, output: 1033.11 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.81it/s, est. speed input: 1227.65 toks/s, output: 1165.11 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:19:55 scheduler.py:1754] Sequence group 17115 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.41it/s, est. speed input: 1154.64 toks/s, output: 1155.65 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:20:11 scheduler.py:1754] Sequence group 17198 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.13it/s, est. speed input: 1319.98 toks/s, output: 1145.54 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.26it/s, est. speed input: 1362.63 toks/s, output: 1137.98 toks/s]\n",
      " 52%|█████▏    | 54/104 [51:08<45:49, 54.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:20:31 scheduler.py:1754] Sequence group 17335 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.22it/s, est. speed input: 1619.05 toks/s, output: 1157.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.50it/s, est. speed input: 1336.44 toks/s, output: 1088.59 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:20:46 scheduler.py:1754] Sequence group 17434 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  9.02it/s, est. speed input: 1912.24 toks/s, output: 1176.76 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.46it/s, est. speed input: 1406.46 toks/s, output: 1086.08 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:21:05 scheduler.py:1754] Sequence group 17582 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.76it/s, est. speed input: 1475.01 toks/s, output: 1119.65 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.24it/s, est. speed input: 1279.45 toks/s, output: 1179.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:21:23 scheduler.py:1754] Sequence group 17693 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.39it/s, est. speed input: 1364.50 toks/s, output: 1133.02 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:21:37 scheduler.py:1754] Sequence group 17783 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.22it/s, est. speed input: 1354.91 toks/s, output: 1140.20 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.85it/s, est. speed input: 1314.33 toks/s, output: 1163.49 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:21:56 scheduler.py:1754] Sequence group 17889 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.14it/s, est. speed input: 1406.06 toks/s, output: 1149.03 toks/s]\n",
      " 54%|█████▍    | 56/104 [52:45<41:37, 52.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:00<00:00, 2611.62it/s, est. speed input: 5370281.68 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:00<00:00, 2619.90it/s, est. speed input: 5386480.04 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:00<00:00, 2009.77it/s, est. speed input: 4143714.63 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:00<00:00, 2237.24it/s, est. speed input: 4598672.71 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:22:04 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:00<00:00, 2369.73it/s, est. speed input: 4871221.64 toks/s, output: 0.00 toks/s]\n",
      " 55%|█████▍    | 57/104 [52:46<28:34, 36.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:22:12 scheduler.py:1754] Sequence group 18297 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.46it/s, est. speed input: 1108.31 toks/s, output: 1199.76 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.25it/s, est. speed input: 1724.64 toks/s, output: 1102.71 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:22:28 scheduler.py:1754] Sequence group 18422 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.57it/s, est. speed input: 1624.39 toks/s, output: 1133.17 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.21it/s, est. speed input: 1354.75 toks/s, output: 1092.32 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:22:44 scheduler.py:1754] Sequence group 18538 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.30it/s, est. speed input: 1400.47 toks/s, output: 1150.94 toks/s]\n",
      " 56%|█████▌    | 58/104 [53:34<30:45, 40.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:22:58 scheduler.py:1754] Sequence group 18601 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.66it/s, est. speed input: 1279.71 toks/s, output: 1128.08 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.63it/s, est. speed input: 1490.13 toks/s, output: 1160.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:23:12 scheduler.py:1754] Sequence group 18718 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.90it/s, est. speed input: 1367.96 toks/s, output: 1093.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:23:24 scheduler.py:1754] Sequence group 18797 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.67it/s, est. speed input: 1344.43 toks/s, output: 1025.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.73it/s, est. speed input: 1793.40 toks/s, output: 1112.23 toks/s]\n",
      " 57%|█████▋    | 59/104 [54:19<31:07, 41.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:23:40 scheduler.py:1754] Sequence group 18929 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.27it/s, est. speed input: 1453.75 toks/s, output: 1093.72 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.87it/s, est. speed input: 1462.36 toks/s, output: 1048.67 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:23:57 scheduler.py:1754] Sequence group 19035 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.65it/s, est. speed input: 1423.39 toks/s, output: 1078.17 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.86it/s, est. speed input: 1909.11 toks/s, output: 1112.77 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:24:14 scheduler.py:1754] Sequence group 19169 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.88it/s, est. speed input: 1927.42 toks/s, output: 1088.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.57it/s, est. speed input: 1287.87 toks/s, output: 1094.34 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:24:32 scheduler.py:1754] Sequence group 19306 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.90it/s, est. speed input: 1190.91 toks/s, output: 1250.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.11it/s, est. speed input: 1267.62 toks/s, output: 1192.38 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:24:53 scheduler.py:1754] Sequence group 19423 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.08it/s, est. speed input: 1280.19 toks/s, output: 1229.70 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:25:09 scheduler.py:1754] Sequence group 19518 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.08it/s, est. speed input: 1299.36 toks/s, output: 1161.00 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.42it/s, est. speed input: 994.18 toks/s, output: 1100.15 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:25:28 scheduler.py:1754] Sequence group 19608 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.37it/s, est. speed input: 990.85 toks/s, output: 1170.49 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:25:45 scheduler.py:1754] Sequence group 19665 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:15<00:00,  4.16it/s, est. speed input: 951.20 toks/s, output: 1187.80 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:26:02 scheduler.py:1754] Sequence group 19740 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.47it/s, est. speed input: 1029.46 toks/s, output: 1162.37 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:26:19 scheduler.py:1754] Sequence group 19821 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:16<00:00,  4.00it/s, est. speed input: 921.21 toks/s, output: 1190.76 toks/s]\n",
      " 60%|█████▉    | 62/104 [57:09<37:46, 53.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:26:34 scheduler.py:1754] Sequence group 19897 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.39it/s, est. speed input: 1120.88 toks/s, output: 1144.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.11it/s, est. speed input: 1689.64 toks/s, output: 1075.41 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:26:52 scheduler.py:1754] Sequence group 20009 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=9951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.69it/s, est. speed input: 1185.00 toks/s, output: 1169.28 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:27:06 scheduler.py:1754] Sequence group 20091 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.22it/s, est. speed input: 1308.22 toks/s, output: 1083.98 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.42it/s, est. speed input: 1358.23 toks/s, output: 1028.15 toks/s]\n",
      " 61%|██████    | 63/104 [58:00<36:20, 53.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:00<00:00, 2732.31it/s, est. speed input: 4151671.56 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:00<00:00, 2516.65it/s, est. speed input: 3823176.24 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:00<00:00, 2710.95it/s, est. speed input: 4119520.35 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:00<00:00, 2388.15it/s, est. speed input: 3627344.28 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 21:27:19 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:00<00:00, 2021.75it/s, est. speed input: 3078197.07 toks/s, output: 0.00 toks/s]\n",
      " 62%|██████▏   | 64/104 [58:00<24:51, 37.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:27:23 scheduler.py:1754] Sequence group 20511 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.06it/s, est. speed input: 1063.58 toks/s, output: 1184.66 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:27:40 scheduler.py:1754] Sequence group 20599 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.19it/s, est. speed input: 1102.14 toks/s, output: 1147.11 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.48it/s, est. speed input: 1178.37 toks/s, output: 1194.98 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:27:58 scheduler.py:1754] Sequence group 20705 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.18it/s, est. speed input: 1121.87 toks/s, output: 1178.35 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:28:13 scheduler.py:1754] Sequence group 20784 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.14it/s, est. speed input: 1330.51 toks/s, output: 1182.42 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.73it/s, est. speed input: 1145.84 toks/s, output: 1212.80 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:28:32 scheduler.py:1754] Sequence group 20893 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.61it/s, est. speed input: 1136.48 toks/s, output: 1197.25 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:28:48 scheduler.py:1754] Sequence group 20987 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.53it/s, est. speed input: 1179.89 toks/s, output: 1215.30 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.95it/s, est. speed input: 1716.35 toks/s, output: 1123.66 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:29:05 scheduler.py:1754] Sequence group 21100 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.23it/s, est. speed input: 1369.20 toks/s, output: 1114.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.45it/s, est. speed input: 1277.69 toks/s, output: 1057.38 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:29:23 scheduler.py:1754] Sequence group 21216 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.37it/s, est. speed input: 1283.34 toks/s, output: 1079.29 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.31it/s, est. speed input: 1699.78 toks/s, output: 1150.97 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:29:40 scheduler.py:1754] Sequence group 21342 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.66it/s, est. speed input: 1590.32 toks/s, output: 1136.54 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:29:52 scheduler.py:1754] Sequence group 21409 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.40it/s, est. speed input: 1340.25 toks/s, output: 1148.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:15<00:00,  4.10it/s, est. speed input: 1708.81 toks/s, output: 1069.61 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:30:22 scheduler.py:1754] Sequence group 21546 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:15<00:00,  4.10it/s, est. speed input: 1712.84 toks/s, output: 1076.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.60it/s, est. speed input: 1507.94 toks/s, output: 1058.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:30:52 scheduler.py:1754] Sequence group 21653 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.57it/s, est. speed input: 1502.49 toks/s, output: 1069.37 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:31:11 scheduler.py:1091] Input prompt (778 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:31:18 scheduler.py:1754] Sequence group 21755 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.65it/s, est. speed input: 1543.23 toks/s, output: 1003.96 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.32it/s, est. speed input: 1112.05 toks/s, output: 1146.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:31:38 scheduler.py:1754] Sequence group 21864 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.43it/s, est. speed input: 1143.49 toks/s, output: 1128.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.12it/s, est. speed input: 1308.00 toks/s, output: 1159.86 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:31:58 scheduler.py:1754] Sequence group 21994 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.00it/s, est. speed input: 1302.70 toks/s, output: 1204.56 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:32:14 scheduler.py:1754] Sequence group 22066 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.58it/s, est. speed input: 1002.16 toks/s, output: 1108.49 toks/s]\n",
      " 66%|██████▋   | 69/104 [1:03:03<33:59, 58.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:32:28 scheduler.py:1754] Sequence group 22133 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.73it/s, est. speed input: 1243.24 toks/s, output: 1148.08 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.75it/s, est. speed input: 1044.55 toks/s, output: 1097.26 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:32:47 scheduler.py:1754] Sequence group 22236 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.03it/s, est. speed input: 1348.74 toks/s, output: 1094.14 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:33:04 scheduler.py:1754] Sequence group 22322 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=10951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.62it/s, est. speed input: 1043.25 toks/s, output: 1098.43 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.87it/s, est. speed input: 1107.89 toks/s, output: 1097.62 toks/s]\n",
      " 67%|██████▋   | 70/104 [1:04:05<33:45, 59.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:33:25 scheduler.py:1754] Sequence group 22424 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.63it/s, est. speed input: 1188.52 toks/s, output: 1228.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:33:40 scheduler.py:1754] Sequence group 22491 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.86it/s, est. speed input: 1267.20 toks/s, output: 1181.43 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.37it/s, est. speed input: 1170.83 toks/s, output: 1174.69 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:34:01 scheduler.py:1754] Sequence group 22626 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  4.96it/s, est. speed input: 1092.33 toks/s, output: 1125.52 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.75it/s, est. speed input: 1270.89 toks/s, output: 1218.79 toks/s]\n",
      " 68%|██████▊   | 71/104 [1:05:04<32:36, 59.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:34:23 scheduler.py:1754] Sequence group 22746 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.33it/s, est. speed input: 1240.05 toks/s, output: 1102.83 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  9.13it/s, est. speed input: 1834.02 toks/s, output: 1211.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:34:41 scheduler.py:1754] Sequence group 22882 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.48it/s, est. speed input: 1321.95 toks/s, output: 1096.73 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.33it/s, est. speed input: 1308.90 toks/s, output: 1147.13 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:35:00 scheduler.py:1754] Sequence group 23002 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.75it/s, est. speed input: 1615.10 toks/s, output: 1133.94 toks/s]\n",
      " 69%|██████▉   | 72/104 [1:05:49<29:24, 55.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:35:16 scheduler.py:1754] Sequence group 23069 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:20<00:00,  3.12it/s, est. speed input: 856.06 toks/s, output: 1122.85 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:35:36 scheduler.py:1754] Sequence group 23139 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:18<00:00,  3.46it/s, est. speed input: 954.87 toks/s, output: 1166.46 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:35:55 scheduler.py:1754] Sequence group 23207 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.57it/s, est. speed input: 983.63 toks/s, output: 1169.87 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:36:14 scheduler.py:1754] Sequence group 23265 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:21<00:00,  2.95it/s, est. speed input: 813.07 toks/s, output: 1154.47 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:36:35 scheduler.py:1754] Sequence group 23331 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:19<00:00,  3.29it/s, est. speed input: 908.66 toks/s, output: 1147.89 toks/s]\n",
      " 70%|███████   | 73/104 [1:07:27<35:09, 68.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:36:52 scheduler.py:1754] Sequence group 23403 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.49it/s, est. speed input: 1271.70 toks/s, output: 1085.97 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.66it/s, est. speed input: 1338.41 toks/s, output: 1019.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:37:09 scheduler.py:1754] Sequence group 23530 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.83it/s, est. speed input: 1407.29 toks/s, output: 1020.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.25it/s, est. speed input: 1319.88 toks/s, output: 1077.13 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:37:26 scheduler.py:1754] Sequence group 23644 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.37it/s, est. speed input: 1817.59 toks/s, output: 1162.91 toks/s]\n",
      " 71%|███████   | 74/104 [1:08:14<30:51, 61.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:37:42 scheduler.py:1754] Sequence group 23726 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:15<00:00,  4.22it/s, est. speed input: 911.99 toks/s, output: 1182.67 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:37:58 scheduler.py:1754] Sequence group 23806 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.00it/s, est. speed input: 1087.73 toks/s, output: 1128.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.47it/s, est. speed input: 978.07 toks/s, output: 1170.82 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:38:17 scheduler.py:1754] Sequence group 23901 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.49it/s, est. speed input: 989.59 toks/s, output: 1148.90 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:38:34 scheduler.py:1754] Sequence group 23955 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.21it/s, est. speed input: 1149.78 toks/s, output: 1175.35 toks/s]\n",
      " 72%|███████▏  | 75/104 [1:09:23<30:52, 63.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:38:49 scheduler.py:1754] Sequence group 24060 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.50it/s, est. speed input: 1332.42 toks/s, output: 1072.02 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.74it/s, est. speed input: 1226.73 toks/s, output: 1186.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:39:05 scheduler.py:1754] Sequence group 24169 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=11951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.65it/s, est. speed input: 1894.65 toks/s, output: 1105.47 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.43it/s, est. speed input: 1429.47 toks/s, output: 1090.50 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:39:22 scheduler.py:1754] Sequence group 24290 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.02it/s, est. speed input: 1348.36 toks/s, output: 1129.61 toks/s]\n",
      " 73%|███████▎  | 76/104 [1:10:12<27:44, 59.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:39:37 scheduler.py:1754] Sequence group 24370 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.44it/s, est. speed input: 1275.02 toks/s, output: 1104.17 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.45it/s, est. speed input: 1332.42 toks/s, output: 1070.29 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:39:53 scheduler.py:1754] Sequence group 24485 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.26it/s, est. speed input: 1326.93 toks/s, output: 1160.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.67it/s, est. speed input: 1439.08 toks/s, output: 1091.42 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:40:12 scheduler.py:1754] Sequence group 24601 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.26it/s, est. speed input: 1377.88 toks/s, output: 1105.61 toks/s]\n",
      " 74%|███████▍  | 77/104 [1:11:03<25:30, 56.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:40:26 scheduler.py:1754] Sequence group 24684 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.88it/s, est. speed input: 1153.24 toks/s, output: 1241.96 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.58it/s, est. speed input: 1311.36 toks/s, output: 1096.36 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:40:44 scheduler.py:1754] Sequence group 24802 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.48it/s, est. speed input: 1321.20 toks/s, output: 1084.16 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:40:57 scheduler.py:1754] Sequence group 24877 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.32it/s, est. speed input: 1298.50 toks/s, output: 1186.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.53it/s, est. speed input: 1401.37 toks/s, output: 1155.32 toks/s]\n",
      " 75%|███████▌  | 78/104 [1:11:54<23:49, 54.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:41:18 scheduler.py:1754] Sequence group 25004 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.06it/s, est. speed input: 1261.22 toks/s, output: 1147.43 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.19it/s, est. speed input: 1310.59 toks/s, output: 1138.63 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:41:36 scheduler.py:1754] Sequence group 25127 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.04it/s, est. speed input: 1291.66 toks/s, output: 1184.65 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:41:51 scheduler.py:1754] Sequence group 25208 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.79it/s, est. speed input: 1239.76 toks/s, output: 1246.10 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.14it/s, est. speed input: 1325.15 toks/s, output: 1183.64 toks/s]\n",
      " 76%|███████▌  | 79/104 [1:12:47<22:40, 54.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:42:08 scheduler.py:1754] Sequence group 25313 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.72it/s, est. speed input: 1230.56 toks/s, output: 1202.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:42:25 scheduler.py:1754] Sequence group 25400 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  4.92it/s, est. speed input: 1071.99 toks/s, output: 1158.02 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.55it/s, est. speed input: 993.31 toks/s, output: 1147.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:42:44 scheduler.py:1754] Sequence group 25497 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.76it/s, est. speed input: 1047.73 toks/s, output: 1123.65 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:42:58 scheduler.py:1754] Sequence group 25565 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.78it/s, est. speed input: 1280.79 toks/s, output: 1205.59 toks/s]\n",
      " 77%|███████▋  | 80/104 [1:13:50<22:47, 56.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:43:14 scheduler.py:1754] Sequence group 25632 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.46it/s, est. speed input: 1108.23 toks/s, output: 1184.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.85it/s, est. speed input: 1223.92 toks/s, output: 1205.19 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:43:33 scheduler.py:1754] Sequence group 25762 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.95it/s, est. speed input: 1273.28 toks/s, output: 1180.93 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:43:46 scheduler.py:1754] Sequence group 25827 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.75it/s, est. speed input: 1259.10 toks/s, output: 1169.41 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.87it/s, est. speed input: 1299.02 toks/s, output: 1191.91 toks/s]\n",
      " 78%|███████▊  | 81/104 [1:14:45<21:41, 56.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:44:05 scheduler.py:1754] Sequence group 25953 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:06<00:00,  9.33it/s, est. speed input: 1745.51 toks/s, output: 1061.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:06<00:00,  9.93it/s, est. speed input: 1942.83 toks/s, output: 1134.29 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:44:22 scheduler.py:1754] Sequence group 26108 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.47it/s, est. speed input: 1736.17 toks/s, output: 1056.21 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:06<00:00,  9.48it/s, est. speed input: 1980.24 toks/s, output: 1068.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.10it/s, est. speed input: 1738.02 toks/s, output: 1069.14 toks/s]\n",
      " 79%|███████▉  | 82/104 [1:15:21<18:28, 50.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:44:42 scheduler.py:1754] Sequence group 26277 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=12951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.24it/s, est. speed input: 1284.68 toks/s, output: 1143.29 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:44:57 scheduler.py:1754] Sequence group 26364 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.13it/s, est. speed input: 1272.03 toks/s, output: 1163.63 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.35it/s, est. speed input: 1109.42 toks/s, output: 1161.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:45:14 scheduler.py:1754] Sequence group 26472 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.79it/s, est. speed input: 1408.95 toks/s, output: 1049.28 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:45:28 scheduler.py:1754] Sequence group 26544 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.96it/s, est. speed input: 1235.43 toks/s, output: 1109.29 toks/s]\n",
      " 80%|███████▉  | 83/104 [1:16:14<17:53, 51.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:45:50 scheduler.py:1754] Sequence group 26622 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:19<00:00,  3.22it/s, est. speed input: 879.47 toks/s, output: 1135.17 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:46:09 scheduler.py:1754] Sequence group 26685 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:21<00:00,  2.99it/s, est. speed input: 819.14 toks/s, output: 1111.43 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:46:30 scheduler.py:1754] Sequence group 26751 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:18<00:00,  3.50it/s, est. speed input: 963.73 toks/s, output: 1183.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:21<00:00,  2.99it/s, est. speed input: 827.50 toks/s, output: 1135.52 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:46:54 scheduler.py:1754] Sequence group 26837 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:18<00:00,  3.53it/s, est. speed input: 977.86 toks/s, output: 1193.29 toks/s]\n",
      " 81%|████████  | 84/104 [1:17:53<21:50, 65.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:47:13 scheduler.py:1754] Sequence group 26912 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  7.07it/s, est. speed input: 1435.90 toks/s, output: 1127.54 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:47:28 scheduler.py:1754] Sequence group 27003 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.76it/s, est. speed input: 1211.93 toks/s, output: 1218.86 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.87it/s, est. speed input: 1280.30 toks/s, output: 1146.87 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:47:45 scheduler.py:1754] Sequence group 27097 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.30it/s, est. speed input: 1398.16 toks/s, output: 1179.66 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:48:00 scheduler.py:1754] Sequence group 27193 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.35it/s, est. speed input: 1438.25 toks/s, output: 1094.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.76it/s, est. speed input: 1004.35 toks/s, output: 1120.59 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:48:18 scheduler.py:1754] Sequence group 27295 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.21it/s, est. speed input: 1099.83 toks/s, output: 1180.05 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:48:33 scheduler.py:1754] Sequence group 27367 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.11it/s, est. speed input: 1288.48 toks/s, output: 1179.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.52it/s, est. speed input: 1165.39 toks/s, output: 1195.59 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:48:52 scheduler.py:1754] Sequence group 27482 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.45it/s, est. speed input: 938.55 toks/s, output: 1174.16 toks/s]\n",
      " 83%|████████▎ | 86/104 [1:19:47<18:28, 61.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:49:07 scheduler.py:1754] Sequence group 27549 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.23it/s, est. speed input: 1067.55 toks/s, output: 1159.05 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:49:22 scheduler.py:1754] Sequence group 27632 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.92it/s, est. speed input: 1224.02 toks/s, output: 1088.03 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.19it/s, est. speed input: 1287.74 toks/s, output: 1137.46 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:49:41 scheduler.py:1754] Sequence group 27748 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.19it/s, est. speed input: 1303.75 toks/s, output: 1145.87 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:49:56 scheduler.py:1754] Sequence group 27837 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.28it/s, est. speed input: 1322.72 toks/s, output: 1103.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:16<00:00,  3.91it/s, est. speed input: 871.03 toks/s, output: 1202.36 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:50:16 scheduler.py:1754] Sequence group 27928 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.77it/s, est. speed input: 1071.35 toks/s, output: 1104.07 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:50:31 scheduler.py:1754] Sequence group 27993 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=13951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:15<00:00,  4.12it/s, est. speed input: 926.33 toks/s, output: 1171.50 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:50:47 scheduler.py:1754] Sequence group 28060 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.41it/s, est. speed input: 995.91 toks/s, output: 1183.34 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:51:04 scheduler.py:1754] Sequence group 28113 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.32it/s, est. speed input: 980.11 toks/s, output: 1198.58 toks/s]\n",
      " 85%|████████▍ | 88/104 [1:21:56<17:03, 63.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:51:19 scheduler.py:1754] Sequence group 28203 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.10it/s, est. speed input: 1085.73 toks/s, output: 1178.20 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:51:34 scheduler.py:1754] Sequence group 28277 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:15<00:00,  4.21it/s, est. speed input: 903.88 toks/s, output: 1225.49 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:51:52 scheduler.py:1754] Sequence group 28344 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.46it/s, est. speed input: 963.08 toks/s, output: 1142.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.53it/s, est. speed input: 1194.50 toks/s, output: 1159.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:52:10 scheduler.py:1754] Sequence group 28450 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.58it/s, est. speed input: 989.11 toks/s, output: 1098.24 toks/s] \n",
      " 86%|████████▌ | 89/104 [1:23:04<16:16, 65.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:52:24 scheduler.py:1754] Sequence group 28516 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.60it/s, est. speed input: 1332.90 toks/s, output: 1082.36 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.68it/s, est. speed input: 1389.78 toks/s, output: 1076.93 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:52:42 scheduler.py:1754] Sequence group 28634 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.95it/s, est. speed input: 1257.31 toks/s, output: 1185.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:52:56 scheduler.py:1754] Sequence group 28708 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.48it/s, est. speed input: 1174.50 toks/s, output: 1192.31 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.61it/s, est. speed input: 1202.58 toks/s, output: 1187.76 toks/s]\n",
      " 87%|████████▋ | 90/104 [1:23:57<14:21, 61.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:53:16 scheduler.py:1754] Sequence group 28827 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.42it/s, est. speed input: 1132.53 toks/s, output: 1216.44 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:53:33 scheduler.py:1754] Sequence group 28889 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.39it/s, est. speed input: 1130.11 toks/s, output: 1124.21 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:53:49 scheduler.py:1754] Sequence group 28988 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:13<00:00,  4.57it/s, est. speed input: 967.20 toks/s, output: 1092.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.46it/s, est. speed input: 1159.11 toks/s, output: 1176.86 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:54:07 scheduler.py:1754] Sequence group 29095 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.06it/s, est. speed input: 1085.45 toks/s, output: 1188.55 toks/s]\n",
      " 88%|████████▊ | 91/104 [1:24:59<13:22, 61.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:54:23 scheduler.py:1754] Sequence group 29178 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.63it/s, est. speed input: 1287.25 toks/s, output: 1088.40 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.79it/s, est. speed input: 1352.75 toks/s, output: 1053.99 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:54:40 scheduler.py:1754] Sequence group 29297 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.62it/s, est. speed input: 1363.01 toks/s, output: 1098.76 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.44it/s, est. speed input: 1368.96 toks/s, output: 1114.56 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:54:59 scheduler.py:1754] Sequence group 29417 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.50it/s, est. speed input: 1386.33 toks/s, output: 1095.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  7.00it/s, est. speed input: 1394.03 toks/s, output: 1101.45 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:55:16 scheduler.py:1754] Sequence group 29531 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.42it/s, est. speed input: 1332.81 toks/s, output: 1061.53 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:55:32 scheduler.py:1754] Sequence group 29605 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.81it/s, est. speed input: 1234.32 toks/s, output: 1183.04 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.25it/s, est. speed input: 1365.15 toks/s, output: 1110.92 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:55:51 scheduler.py:1754] Sequence group 29740 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.40it/s, est. speed input: 1415.31 toks/s, output: 1182.96 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.53it/s, est. speed input: 1273.46 toks/s, output: 1157.24 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:56:09 scheduler.py:1754] Sequence group 29868 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=14951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.49it/s, est. speed input: 1533.58 toks/s, output: 1042.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.27it/s, est. speed input: 1544.89 toks/s, output: 1048.67 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:56:28 scheduler.py:1754] Sequence group 29993 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.72it/s, est. speed input: 1459.53 toks/s, output: 1038.89 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.48it/s, est. speed input: 1417.42 toks/s, output: 1064.18 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:02<00:00, 22.59it/s, est. speed input: 16849.90 toks/s, output: 493.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:56:47 scheduler.py:1091] Input prompt (816 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:02<00:00, 23.30it/s, est. speed input: 17407.09 toks/s, output: 516.60 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:56:50 scheduler.py:1091] Input prompt (816 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:02<00:00, 23.18it/s, est. speed input: 17319.84 toks/s, output: 511.47 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:56:53 scheduler.py:1091] Input prompt (816 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:02<00:00, 23.28it/s, est. speed input: 17393.65 toks/s, output: 501.65 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:56:56 scheduler.py:1091] Input prompt (816 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:02<00:00, 22.98it/s, est. speed input: 17166.35 toks/s, output: 498.68 toks/s]\n",
      " 91%|█████████▏| 95/104 [1:27:39<06:11, 41.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:57:00 scheduler.py:1754] Sequence group 30436 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.01it/s, est. speed input: 1226.60 toks/s, output: 1128.42 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:57:15 scheduler.py:1754] Sequence group 30507 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.11it/s, est. speed input: 1305.58 toks/s, output: 1148.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.26it/s, est. speed input: 1364.97 toks/s, output: 1143.03 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:57:34 scheduler.py:1754] Sequence group 30629 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.16it/s, est. speed input: 1364.52 toks/s, output: 1123.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.87it/s, est. speed input: 1317.19 toks/s, output: 1169.53 toks/s]\n",
      " 92%|█████████▏| 96/104 [1:28:33<05:59, 44.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:57:55 scheduler.py:1754] Sequence group 30754 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  4.94it/s, est. speed input: 1047.62 toks/s, output: 1171.16 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:58:09 scheduler.py:1754] Sequence group 30814 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.68it/s, est. speed input: 1224.86 toks/s, output: 1110.39 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:58:25 scheduler.py:1754] Sequence group 30899 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:14<00:00,  4.42it/s, est. speed input: 976.69 toks/s, output: 1183.85 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:58:41 scheduler.py:1754] Sequence group 30975 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:12<00:00,  5.16it/s, est. speed input: 1149.29 toks/s, output: 1160.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.17it/s, est. speed input: 1375.31 toks/s, output: 1161.03 toks/s]\n",
      " 93%|█████████▎| 97/104 [1:29:34<05:49, 49.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:58:56 scheduler.py:1754] Sequence group 31078 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.09it/s, est. speed input: 1223.78 toks/s, output: 1232.72 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.45it/s, est. speed input: 1336.87 toks/s, output: 1160.28 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:59:15 scheduler.py:1754] Sequence group 31200 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.50it/s, est. speed input: 1166.74 toks/s, output: 1171.20 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:59:32 scheduler.py:1754] Sequence group 31294 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  7.02it/s, est. speed input: 1531.51 toks/s, output: 1061.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.58it/s, est. speed input: 1247.93 toks/s, output: 1189.47 toks/s]\n",
      " 94%|█████████▍| 98/104 [1:30:28<05:05, 50.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 21:59:49 scheduler.py:1754] Sequence group 31407 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.92it/s, est. speed input: 1201.78 toks/s, output: 1200.85 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  5.96it/s, est. speed input: 1235.00 toks/s, output: 1173.43 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:00:09 scheduler.py:1754] Sequence group 31515 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.26it/s, est. speed input: 1299.48 toks/s, output: 1190.67 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:00:22 scheduler.py:1754] Sequence group 31603 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.61it/s, est. speed input: 1379.09 toks/s, output: 1099.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.62it/s, est. speed input: 1383.53 toks/s, output: 1056.60 toks/s]\n",
      " 95%|█████████▌| 99/104 [1:31:19<04:15, 51.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:00:40 scheduler.py:1754] Sequence group 31720 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.44it/s, est. speed input: 1249.20 toks/s, output: 1082.98 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  8.24it/s, est. speed input: 1686.29 toks/s, output: 1127.28 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:07<00:00,  9.10it/s, est. speed input: 1918.13 toks/s, output: 1107.10 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:01:04 scheduler.py:1754] Sequence group 31910 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.35it/s, est. speed input: 1358.69 toks/s, output: 1162.79 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.81it/s, est. speed input: 1464.30 toks/s, output: 1030.00 toks/s]\n",
      " 96%|█████████▌| 100/104 [1:32:04<03:16, 49.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:01:23 scheduler.py:1754] Sequence group 32019 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.57it/s, est. speed input: 1102.08 toks/s, output: 1115.28 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:01:43 scheduler.py:1754] Sequence group 32078 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:16<00:00,  3.89it/s, est. speed input: 1207.04 toks/s, output: 1143.07 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:02:04 scheduler.py:1754] Sequence group 32155 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:17<00:00,  3.67it/s, est. speed input: 1141.68 toks/s, output: 1141.50 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:02:24 scheduler.py:1754] Sequence group 32234 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=15951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:20<00:00,  3.18it/s, est. speed input: 990.53 toks/s, output: 1119.37 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:02:48 scheduler.py:1754] Sequence group 32300 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=16001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:19<00:00,  3.22it/s, est. speed input: 1007.22 toks/s, output: 1088.79 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.22it/s, est. speed input: 1263.22 toks/s, output: 1126.80 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:03:05 scheduler.py:1754] Sequence group 32409 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=16051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.80it/s, est. speed input: 1197.44 toks/s, output: 1194.99 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:03:18 scheduler.py:1754] Sequence group 32479 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=16101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.72it/s, est. speed input: 1402.03 toks/s, output: 1100.20 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:03:31 scheduler.py:1754] Sequence group 32571 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=16151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.43it/s, est. speed input: 1349.76 toks/s, output: 1066.87 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.39it/s, est. speed input: 1343.97 toks/s, output: 1110.30 toks/s]\n",
      " 98%|█████████▊| 102/104 [1:34:27<01:57, 58.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:03:48 scheduler.py:1754] Sequence group 32695 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=16201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:08<00:00,  7.12it/s, est. speed input: 1460.44 toks/s, output: 1076.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:10<00:00,  6.23it/s, est. speed input: 1320.45 toks/s, output: 1167.92 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:04:07 scheduler.py:1754] Sequence group 32809 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=16251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.49it/s, est. speed input: 1398.91 toks/s, output: 1048.83 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:04:23 scheduler.py:1754] Sequence group 32892 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=16301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 64/64 [00:11<00:00,  5.72it/s, est. speed input: 1252.54 toks/s, output: 1257.46 toks/s]\n",
      "Processed prompts: 100%|██████████| 64/64 [00:09<00:00,  6.60it/s, est. speed input: 1462.95 toks/s, output: 1131.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 43/43 [00:05<00:00,  7.18it/s, est. speed input: 1385.93 toks/s, output: 1113.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 22:04:44 scheduler.py:1754] Sequence group 33044 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=16351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 43/43 [00:05<00:00,  8.12it/s, est. speed input: 1610.18 toks/s, output: 1048.63 toks/s]\n",
      "Processed prompts: 100%|██████████| 43/43 [00:06<00:00,  6.77it/s, est. speed input: 1390.64 toks/s, output: 1098.71 toks/s]\n",
      "Processed prompts: 100%|██████████| 43/43 [00:05<00:00,  7.17it/s, est. speed input: 1505.68 toks/s, output: 1082.06 toks/s]\n",
      "Processed prompts: 100%|██████████| 43/43 [00:06<00:00,  7.13it/s, est. speed input: 1508.46 toks/s, output: 1184.66 toks/s]\n",
      "100%|██████████| 104/104 [1:35:47<00:00, 55.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score: 0.0789\n",
      "Average tools used: 0.0561\n",
      "Average calls per sample: 3.0968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from pretrained peft model\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.lora.request import LoRARequest\n",
    "\n",
    "\n",
    "def load_model(model_name_or_path, peft_model_id):\n",
    "    # Load the base model\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, device_map=\"auto\", torch_dtype='auto')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "    # Load the PEFT model\n",
    "    peft_model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "    \n",
    "    return peft_model, tokenizer\n",
    "\n",
    "model, tokenizer = load_model(\"Qwen/Qwen2.5-0.5B-Instruct\", 'models/sft_base_qwen')\n",
    "vllm_lora_adapter = 'models/sft_base_qwen'\n",
    "base_model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "inference_engine = LLM(\n",
    "    model=base_model_name,\n",
    "    enable_lora=True,\n",
    "    max_lora_rank=64,\n",
    "    max_loras=1,\n",
    "    gpu_memory_utilization=0.2,\n",
    "    # enable_prefix_caching=True,\n",
    "    swap_space=6,\n",
    "    scheduling_policy=\"fcfs\",\n",
    "    dtype=torch.bfloat16,\n",
    "    max_model_len=768,\n",
    "    # enable_sleep_mode=True,\n",
    "    )\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Evaluate the model\n",
    "avg_bleu, tools_used_avg, calls_per_sample_avg = evaluate_model(inference_engine, tokenizer, dataloader, actions_num=4, lora_request=LoRARequest('adapter', 1, vllm_lora_adapter), tools=TOOLS)\n",
    "print(f\"Average BLEU score: {avg_bleu:.4f}\")\n",
    "print(f\"Average tools used: {tools_used_avg:.4f}\")\n",
    "print(f\"Average calls per sample: {calls_per_sample_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7da6b6",
   "metadata": {},
   "source": [
    "## Model with SFT + RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57afea76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-09 19:02:54,546] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-09 19:03:00 __init__.py:207] Automatically detected platform cuda.\n",
      "INFO 05-09 19:03:05 config.py:549] This model supports multiple tasks: {'classify', 'generate', 'reward', 'score', 'embed'}. Defaulting to 'generate'.\n",
      "INFO 05-09 19:03:05 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='Qwen/Qwen2.5-0.5B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-0.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-0.5B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "WARNING 05-09 19:03:05 interface.py:304] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 05-09 19:03:06 cuda.py:229] Using Flash Attention backend.\n",
      "INFO 05-09 19:03:06 model_runner.py:1110] Starting to load model Qwen/Qwen2.5-0.5B-Instruct...\n",
      "INFO 05-09 19:03:06 weight_utils.py:254] Using model weights format ['*.safetensors']\n",
      "INFO 05-09 19:03:06 weight_utils.py:304] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.36it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-09 19:03:07 model_runner.py:1115] Loading model weights took 0.9254 GB\n",
      "INFO 05-09 19:03:07 punica_selector.py:18] Using PunicaWrapperGPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-09 19:03:09 worker.py:267] Memory profiling takes 2.08 seconds\n",
      "INFO 05-09 19:03:09 worker.py:267] the current vLLM instance can use total_gpu_memory (11.99GiB) x gpu_memory_utilization (0.20) = 2.40GiB\n",
      "INFO 05-09 19:03:09 worker.py:267] model weights take 0.93GiB; non_torch_memory takes 0.02GiB; PyTorch activation peak memory takes 1.39GiB; the rest of the memory reserved for KV Cache is 0.07GiB.\n",
      "INFO 05-09 19:03:09 executor_base.py:111] # cuda blocks: 375, # CPU blocks: 32768\n",
      "INFO 05-09 19:03:09 executor_base.py:116] Maximum concurrency for 768 tokens per request: 7.81x\n",
      "INFO 05-09 19:03:10 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:11<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-09 19:03:21 model_runner.py:1562] Graph capturing finished in 12 secs, took 0.31 GiB\n",
      "INFO 05-09 19:03:21 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.72 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/139 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:03:22 tokenizer.py:264] No tokenizer found in models/grpo_policy_model, using base model tokenizer instead. (Exception: Unrecognized model in models/grpo_policy_model. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v3, deformable_detr, deit, depth_anything, depth_pro, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, git, glm, glm4, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mistral3, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_vl, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam_vision_model, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, textnet, time_series_transformer, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zamba2, zoedepth)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135595/2621217833.py:111: DeprecationWarning: The keyword arguments {'prompt_token_ids'} are deprecated and will be removed in a future update. Please use the 'prompts' parameter instead.\n",
      "  outputs, tools_used, how_many_tool_calls = generate_batch_completion(model, tokenizer, inputs, actions_num=actions_num, lora_request=lora_request, tools=tools)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:03:22 scheduler.py:1754] Sequence group 30 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.15it/s, est. speed input: 1756.78 toks/s, output: 875.72 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.35it/s, est. speed input: 1603.90 toks/s, output: 1025.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.34it/s, est. speed input: 1601.79 toks/s, output: 1080.37 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:03:40 scheduler.py:1754] Sequence group 189 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.62it/s, est. speed input: 1654.13 toks/s, output: 1118.37 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 11.85it/s, est. speed input: 2277.06 toks/s, output: 751.60 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.35it/s, est. speed input: 1696.01 toks/s, output: 1170.53 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.17it/s, est. speed input: 1861.40 toks/s, output: 1015.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.34it/s, est. speed input: 1897.49 toks/s, output: 882.34 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:04:07 scheduler.py:1754] Sequence group 430 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.71it/s, est. speed input: 1565.27 toks/s, output: 996.28 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.53it/s, est. speed input: 1528.04 toks/s, output: 1096.63 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.93it/s, est. speed input: 1927.24 toks/s, output: 965.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:03<00:00, 14.25it/s, est. speed input: 2779.42 toks/s, output: 1037.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.08it/s, est. speed input: 1771.58 toks/s, output: 991.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.50it/s, est. speed input: 1657.91 toks/s, output: 1033.58 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:04:38 scheduler.py:1754] Sequence group 713 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.31it/s, est. speed input: 1814.46 toks/s, output: 1017.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.36it/s, est. speed input: 1623.81 toks/s, output: 1087.67 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.24it/s, est. speed input: 1588.31 toks/s, output: 1103.43 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:05:05 scheduler.py:1754] Sequence group 853 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:11<00:00,  4.04it/s, est. speed input: 1224.77 toks/s, output: 1036.56 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:12<00:00,  3.90it/s, est. speed input: 1183.21 toks/s, output: 1096.90 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:05:27 scheduler.py:1754] Sequence group 934 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:12<00:00,  3.97it/s, est. speed input: 1202.64 toks/s, output: 1072.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.40it/s, est. speed input: 1966.51 toks/s, output: 903.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.99it/s, est. speed input: 1699.14 toks/s, output: 970.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.81it/s, est. speed input: 1854.02 toks/s, output: 966.45 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:05:52 scheduler.py:1754] Sequence group 1139 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.86it/s, est. speed input: 1863.78 toks/s, output: 992.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.72it/s, est. speed input: 1836.68 toks/s, output: 911.05 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.84it/s, est. speed input: 1741.25 toks/s, output: 920.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.87it/s, est. speed input: 1551.53 toks/s, output: 1182.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.27it/s, est. speed input: 1433.30 toks/s, output: 1169.40 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.95it/s, est. speed input: 1959.54 toks/s, output: 929.20 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:06:24 scheduler.py:1754] Sequence group 1419 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.72it/s, est. speed input: 1914.71 toks/s, output: 955.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.34it/s, est. speed input: 2027.46 toks/s, output: 960.28 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.02it/s, est. speed input: 1585.05 toks/s, output: 1140.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.66it/s, est. speed input: 1929.78 toks/s, output: 930.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.52it/s, est. speed input: 1702.60 toks/s, output: 1105.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.43it/s, est. speed input: 2083.70 toks/s, output: 910.90 toks/s]\n",
      "  5%|▌         | 7/139 [03:32<1:04:43, 29.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:06:55 scheduler.py:1754] Sequence group 1707 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.79it/s, est. speed input: 1740.74 toks/s, output: 1021.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.24it/s, est. speed input: 1649.98 toks/s, output: 1154.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.03it/s, est. speed input: 1808.75 toks/s, output: 1011.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.35it/s, est. speed input: 1872.95 toks/s, output: 1059.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.18it/s, est. speed input: 1638.05 toks/s, output: 1125.99 toks/s]\n",
      "  6%|▌         | 8/139 [04:00<1:03:01, 28.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:07:23 scheduler.py:1754] Sequence group 1952 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.07it/s, est. speed input: 1491.11 toks/s, output: 1083.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.04it/s, est. speed input: 1696.26 toks/s, output: 1213.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.26it/s, est. speed input: 1532.39 toks/s, output: 1162.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:07:44 scheduler.py:1754] Sequence group 2111 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.73it/s, est. speed input: 1421.01 toks/s, output: 1084.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.59it/s, est. speed input: 1178.82 toks/s, output: 1080.47 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.88it/s, est. speed input: 2110.52 toks/s, output: 1047.78 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.11it/s, est. speed input: 1993.27 toks/s, output: 926.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.64it/s, est. speed input: 1900.09 toks/s, output: 863.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.66it/s, est. speed input: 1707.99 toks/s, output: 968.07 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:08:17 scheduler.py:1754] Sequence group 2378 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.16it/s, est. speed input: 1806.88 toks/s, output: 991.85 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:11<00:00,  4.19it/s, est. speed input: 1035.67 toks/s, output: 1107.47 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:08:37 scheduler.py:1754] Sequence group 2483 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.06it/s, est. speed input: 1249.53 toks/s, output: 1113.79 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.10it/s, est. speed input: 1258.75 toks/s, output: 1101.08 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.01it/s, est. speed input: 1237.30 toks/s, output: 1119.06 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:09:04 scheduler.py:1754] Sequence group 2623 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:10<00:00,  4.44it/s, est. speed input: 1097.35 toks/s, output: 1165.29 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.96it/s, est. speed input: 1742.63 toks/s, output: 1122.46 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.31it/s, est. speed input: 1381.11 toks/s, output: 1050.68 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:09:27 scheduler.py:1754] Sequence group 2764 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.48it/s, est. speed input: 1857.72 toks/s, output: 1070.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  6.87it/s, est. speed input: 1504.51 toks/s, output: 1052.67 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.80it/s, est. speed input: 1709.32 toks/s, output: 1056.78 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.32it/s, est. speed input: 1742.85 toks/s, output: 923.85 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:09:52 scheduler.py:1754] Sequence group 2967 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.30it/s, est. speed input: 1982.09 toks/s, output: 964.34 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.02it/s, est. speed input: 1952.76 toks/s, output: 941.41 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.46it/s, est. speed input: 2037.77 toks/s, output: 916.61 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.62it/s, est. speed input: 2069.11 toks/s, output: 827.20 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.10it/s, est. speed input: 1685.61 toks/s, output: 1161.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.16it/s, est. speed input: 1715.07 toks/s, output: 1010.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:10:21 scheduler.py:1754] Sequence group 3243 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.78it/s, est. speed input: 1844.67 toks/s, output: 1054.93 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.90it/s, est. speed input: 1870.32 toks/s, output: 1136.54 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.39it/s, est. speed input: 1343.25 toks/s, output: 1119.37 toks/s]\n",
      " 10%|█         | 14/139 [07:17<1:04:45, 31.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:10:41 scheduler.py:1754] Sequence group 3400 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.79it/s, est. speed input: 1775.47 toks/s, output: 1104.54 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.14it/s, est. speed input: 1853.50 toks/s, output: 1069.59 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.66it/s, est. speed input: 1756.42 toks/s, output: 1009.96 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.51it/s, est. speed input: 1320.15 toks/s, output: 1116.54 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.25it/s, est. speed input: 1673.72 toks/s, output: 1199.91 toks/s]\n",
      " 11%|█         | 15/139 [07:47<1:03:15, 30.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:11:09 scheduler.py:1754] Sequence group 3627 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.00it/s, est. speed input: 2069.50 toks/s, output: 990.38 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.57it/s, est. speed input: 1152.86 toks/s, output: 984.26 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:11:25 scheduler.py:1754] Sequence group 3736 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.06it/s, est. speed input: 1462.04 toks/s, output: 1122.58 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.39it/s, est. speed input: 1530.44 toks/s, output: 1119.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.84it/s, est. speed input: 1208.41 toks/s, output: 1077.06 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.06it/s, est. speed input: 1711.78 toks/s, output: 1014.57 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:11:51 scheduler.py:1754] Sequence group 3930 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.73it/s, est. speed input: 1839.12 toks/s, output: 969.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.53it/s, est. speed input: 1611.88 toks/s, output: 1066.06 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.78it/s, est. speed input: 1848.71 toks/s, output: 943.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.38it/s, est. speed input: 1772.35 toks/s, output: 936.38 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.84it/s, est. speed input: 1776.74 toks/s, output: 1093.88 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.41it/s, est. speed input: 1707.71 toks/s, output: 1112.41 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:12:21 scheduler.py:1754] Sequence group 4203 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.11it/s, est. speed input: 1665.46 toks/s, output: 1054.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.70it/s, est. speed input: 1786.70 toks/s, output: 975.88 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  6.93it/s, est. speed input: 1422.65 toks/s, output: 1133.21 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.07it/s, est. speed input: 1478.29 toks/s, output: 1114.46 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:12:47 scheduler.py:1754] Sequence group 4398 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.79it/s, est. speed input: 1837.91 toks/s, output: 999.20 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.00it/s, est. speed input: 1462.16 toks/s, output: 1119.21 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.91it/s, est. speed input: 1234.66 toks/s, output: 1122.04 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:13:07 scheduler.py:1754] Sequence group 4536 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.93it/s, est. speed input: 1657.48 toks/s, output: 1172.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:13<00:00,  3.56it/s, est. speed input: 1053.13 toks/s, output: 1142.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:13:29 scheduler.py:1754] Sequence group 4633 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  4.95it/s, est. speed input: 1466.33 toks/s, output: 1111.41 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:10<00:00,  4.65it/s, est. speed input: 1377.90 toks/s, output: 1093.26 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:13:52 scheduler.py:1754] Sequence group 4740 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:12<00:00,  3.91it/s, est. speed input: 1158.14 toks/s, output: 1083.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:12<00:00,  3.76it/s, est. speed input: 1112.71 toks/s, output: 1107.30 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.91it/s, est. speed input: 1738.04 toks/s, output: 962.97 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:14:18 scheduler.py:1754] Sequence group 4887 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.79it/s, est. speed input: 1713.49 toks/s, output: 1023.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.84it/s, est. speed input: 1919.22 toks/s, output: 828.17 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.50it/s, est. speed input: 1658.02 toks/s, output: 1066.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.06it/s, est. speed input: 1571.54 toks/s, output: 1064.65 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.84it/s, est. speed input: 1638.16 toks/s, output: 1058.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:14:47 scheduler.py:1754] Sequence group 5129 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.32it/s, est. speed input: 1119.97 toks/s, output: 1052.71 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.74it/s, est. speed input: 1419.72 toks/s, output: 1092.71 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.57it/s, est. speed input: 1593.64 toks/s, output: 1056.28 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.25it/s, est. speed input: 1737.94 toks/s, output: 1063.36 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.58it/s, est. speed input: 1673.48 toks/s, output: 1086.33 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:15:19 scheduler.py:1754] Sequence group 5358 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.23it/s, est. speed input: 1630.71 toks/s, output: 1133.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.02it/s, est. speed input: 1985.61 toks/s, output: 896.85 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.41it/s, est. speed input: 1863.36 toks/s, output: 1074.83 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.63it/s, est. speed input: 1709.88 toks/s, output: 1007.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.20it/s, est. speed input: 1998.45 toks/s, output: 943.99 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.00it/s, est. speed input: 1811.01 toks/s, output: 991.08 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.56it/s, est. speed input: 1735.44 toks/s, output: 1018.25 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:15:57 scheduler.py:1754] Sequence group 5694 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.62it/s, est. speed input: 1747.60 toks/s, output: 952.82 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.61it/s, est. speed input: 1746.13 toks/s, output: 1119.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.64it/s, est. speed input: 1496.85 toks/s, output: 1154.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.92it/s, est. speed input: 1760.49 toks/s, output: 999.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.69it/s, est. speed input: 1715.79 toks/s, output: 1055.61 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.01it/s, est. speed input: 1779.30 toks/s, output: 1029.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.01it/s, est. speed input: 1778.30 toks/s, output: 1054.11 toks/s]\n",
      " 18%|█▊        | 25/139 [13:13<57:10, 30.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:16:35 scheduler.py:1754] Sequence group 6030 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.64it/s, est. speed input: 1598.20 toks/s, output: 1181.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.00it/s, est. speed input: 1869.55 toks/s, output: 958.96 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.28it/s, est. speed input: 1735.02 toks/s, output: 1096.96 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.08it/s, est. speed input: 1697.18 toks/s, output: 1018.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.68it/s, est. speed input: 1622.39 toks/s, output: 1114.39 toks/s]\n",
      " 19%|█▊        | 26/139 [13:39<54:34, 28.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:17:03 scheduler.py:1754] Sequence group 6280 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.78it/s, est. speed input: 1594.87 toks/s, output: 1099.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.63it/s, est. speed input: 1153.37 toks/s, output: 1027.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.17it/s, est. speed input: 1676.19 toks/s, output: 1039.44 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:17:24 scheduler.py:1754] Sequence group 6431 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.31it/s, est. speed input: 2113.28 toks/s, output: 904.80 toks/s] \n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.33it/s, est. speed input: 1297.29 toks/s, output: 1105.46 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.93it/s, est. speed input: 1896.57 toks/s, output: 944.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.09it/s, est. speed input: 1756.83 toks/s, output: 1105.41 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:17:45 scheduler.py:1754] Sequence group 6610 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.34it/s, est. speed input: 2016.16 toks/s, output: 920.04 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.12it/s, est. speed input: 1972.35 toks/s, output: 874.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:02<00:00, 16.85it/s, est. speed input: 3284.93 toks/s, output: 1098.02 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.15it/s, est. speed input: 1998.80 toks/s, output: 1007.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.27it/s, est. speed input: 1629.83 toks/s, output: 1115.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.23it/s, est. speed input: 1818.86 toks/s, output: 918.08 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:18:14 scheduler.py:1754] Sequence group 6907 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.13it/s, est. speed input: 1798.93 toks/s, output: 1044.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.18it/s, est. speed input: 1808.86 toks/s, output: 1033.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:03<00:00, 13.38it/s, est. speed input: 2448.62 toks/s, output: 797.25 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 11.67it/s, est. speed input: 2172.07 toks/s, output: 847.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.27it/s, est. speed input: 1725.66 toks/s, output: 971.85 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.07it/s, est. speed input: 1874.74 toks/s, output: 953.00 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 11.85it/s, est. speed input: 2205.67 toks/s, output: 789.94 toks/s]\n",
      " 22%|██▏       | 30/139 [15:22<46:37, 25.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:18:46 scheduler.py:1754] Sequence group 7235 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.03it/s, est. speed input: 1797.81 toks/s, output: 1005.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.79it/s, est. speed input: 1781.34 toks/s, output: 1013.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.18it/s, est. speed input: 1861.05 toks/s, output: 935.30 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.83it/s, est. speed input: 1586.39 toks/s, output: 1175.60 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.20it/s, est. speed input: 1662.72 toks/s, output: 1169.27 toks/s]\n",
      " 22%|██▏       | 31/139 [15:50<47:29, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:19:15 scheduler.py:1754] Sequence group 7482 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.57it/s, est. speed input: 1425.91 toks/s, output: 1124.88 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  6.98it/s, est. speed input: 1515.62 toks/s, output: 1094.08 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.09it/s, est. speed input: 1537.79 toks/s, output: 1128.53 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:19:36 scheduler.py:1754] Sequence group 7626 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.42it/s, est. speed input: 1176.43 toks/s, output: 1027.12 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.19it/s, est. speed input: 1560.31 toks/s, output: 1157.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.57it/s, est. speed input: 2040.51 toks/s, output: 839.20 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.77it/s, est. speed input: 1886.63 toks/s, output: 1043.71 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:20:00 scheduler.py:1754] Sequence group 7818 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.15it/s, est. speed input: 1572.65 toks/s, output: 1127.37 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.43it/s, est. speed input: 1820.72 toks/s, output: 1019.04 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.56it/s, est. speed input: 1460.35 toks/s, output: 1149.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  4.96it/s, est. speed input: 1595.86 toks/s, output: 1046.35 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:20:32 scheduler.py:1754] Sequence group 8010 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:10<00:00,  4.37it/s, est. speed input: 1405.76 toks/s, output: 1002.30 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:11<00:00,  4.05it/s, est. speed input: 1302.92 toks/s, output: 1054.49 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.66it/s, est. speed input: 1823.06 toks/s, output: 1056.97 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:20:59 scheduler.py:1754] Sequence group 8127 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:11<00:00,  4.23it/s, est. speed input: 1361.67 toks/s, output: 1026.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.69it/s, est. speed input: 1765.12 toks/s, output: 1003.56 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.04it/s, est. speed input: 1834.54 toks/s, output: 1046.61 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.03it/s, est. speed input: 1629.57 toks/s, output: 1090.89 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:21:26 scheduler.py:1754] Sequence group 8335 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.03it/s, est. speed input: 1630.55 toks/s, output: 1065.61 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.69it/s, est. speed input: 1358.85 toks/s, output: 1131.12 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.66it/s, est. speed input: 1746.60 toks/s, output: 1117.48 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:21:49 scheduler.py:1754] Sequence group 8491 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.97it/s, est. speed input: 1362.02 toks/s, output: 1021.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.14it/s, est. speed input: 1172.44 toks/s, output: 1082.34 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.36it/s, est. speed input: 1450.37 toks/s, output: 1053.05 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:22:10 scheduler.py:1754] Sequence group 8619 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.26it/s, est. speed input: 1198.48 toks/s, output: 1078.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.63it/s, est. speed input: 1725.11 toks/s, output: 1022.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.38it/s, est. speed input: 1675.36 toks/s, output: 1072.40 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:22:31 scheduler.py:1754] Sequence group 8773 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.55it/s, est. speed input: 1911.00 toks/s, output: 961.67 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.96it/s, est. speed input: 1791.63 toks/s, output: 1043.25 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.14it/s, est. speed input: 1827.41 toks/s, output: 1005.07 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.10it/s, est. speed input: 1691.98 toks/s, output: 1039.44 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.58it/s, est. speed input: 1585.18 toks/s, output: 1112.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.50it/s, est. speed input: 1776.71 toks/s, output: 1016.93 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:23:05 scheduler.py:1754] Sequence group 9060 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.52it/s, est. speed input: 1780.84 toks/s, output: 1097.04 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.99it/s, est. speed input: 1877.98 toks/s, output: 1108.40 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.53it/s, est. speed input: 1238.75 toks/s, output: 1028.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.58it/s, est. speed input: 1474.49 toks/s, output: 1022.48 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:23:31 scheduler.py:1754] Sequence group 9244 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.55it/s, est. speed input: 1466.61 toks/s, output: 1047.98 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.58it/s, est. speed input: 1698.37 toks/s, output: 1083.12 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:23:48 scheduler.py:1754] Sequence group 9348 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.38it/s, est. speed input: 1204.87 toks/s, output: 1061.21 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.34it/s, est. speed input: 1803.44 toks/s, output: 1004.89 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.04it/s, est. speed input: 1771.97 toks/s, output: 1056.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:02<00:00, 17.61it/s, est. speed input: 3451.51 toks/s, output: 1026.68 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.72it/s, est. speed input: 1904.48 toks/s, output: 1005.00 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.54it/s, est. speed input: 1868.76 toks/s, output: 1009.60 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.08it/s, est. speed input: 1952.03 toks/s, output: 935.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:24:22 scheduler.py:1754] Sequence group 9673 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.28it/s, est. speed input: 1135.98 toks/s, output: 1082.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.44it/s, est. speed input: 1600.31 toks/s, output: 1032.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.11it/s, est. speed input: 1744.26 toks/s, output: 1172.47 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:24:45 scheduler.py:1754] Sequence group 9832 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.69it/s, est. speed input: 1438.50 toks/s, output: 1058.52 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.50it/s, est. speed input: 1560.09 toks/s, output: 1104.12 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.86it/s, est. speed input: 1843.21 toks/s, output: 927.14 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:25:06 scheduler.py:1754] Sequence group 9977 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.68it/s, est. speed input: 1180.66 toks/s, output: 1024.44 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.29it/s, est. speed input: 1308.52 toks/s, output: 1032.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.84it/s, est. speed input: 1631.70 toks/s, output: 1126.86 toks/s]\n",
      " 30%|███       | 42/139 [22:02<52:23, 32.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:25:26 scheduler.py:1754] Sequence group 10115 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.21it/s, est. speed input: 1666.56 toks/s, output: 1096.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.83it/s, est. speed input: 1397.70 toks/s, output: 1089.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.68it/s, est. speed input: 1981.66 toks/s, output: 823.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.42it/s, est. speed input: 1929.35 toks/s, output: 999.72 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.59it/s, est. speed input: 1758.51 toks/s, output: 1080.52 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.85it/s, est. speed input: 2072.17 toks/s, output: 870.64 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:25:58 scheduler.py:1754] Sequence group 10399 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.61it/s, est. speed input: 1852.25 toks/s, output: 1028.36 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.48it/s, est. speed input: 2020.83 toks/s, output: 885.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.79it/s, est. speed input: 2079.85 toks/s, output: 888.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.96it/s, est. speed input: 1726.43 toks/s, output: 1004.79 toks/s]\n",
      " 32%|███▏      | 44/139 [22:55<45:57, 29.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:26:18 scheduler.py:1754] Sequence group 10601 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.30it/s, est. speed input: 1700.80 toks/s, output: 1084.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.68it/s, est. speed input: 1789.30 toks/s, output: 1003.83 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.56it/s, est. speed input: 1971.35 toks/s, output: 933.49 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.78it/s, est. speed input: 1810.03 toks/s, output: 1052.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.41it/s, est. speed input: 2146.85 toks/s, output: 828.11 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.73it/s, est. speed input: 1736.39 toks/s, output: 1023.80 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:26:51 scheduler.py:1754] Sequence group 10894 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.79it/s, est. speed input: 1749.04 toks/s, output: 974.86 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.59it/s, est. speed input: 1709.72 toks/s, output: 953.30 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.36it/s, est. speed input: 1663.13 toks/s, output: 1057.74 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.06it/s, est. speed input: 1803.40 toks/s, output: 1096.73 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.39it/s, est. speed input: 1694.56 toks/s, output: 1100.34 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.98it/s, est. speed input: 1819.40 toks/s, output: 986.26 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:27:23 scheduler.py:1754] Sequence group 11170 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.04it/s, est. speed input: 1830.99 toks/s, output: 1042.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.80it/s, est. speed input: 1782.63 toks/s, output: 1052.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.27it/s, est. speed input: 1877.04 toks/s, output: 1028.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.37it/s, est. speed input: 1408.82 toks/s, output: 1176.47 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.77it/s, est. speed input: 1865.22 toks/s, output: 1071.77 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:27:50 scheduler.py:1754] Sequence group 11406 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.22it/s, est. speed input: 1951.48 toks/s, output: 906.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.32it/s, est. speed input: 1780.51 toks/s, output: 1027.36 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.75it/s, est. speed input: 1480.14 toks/s, output: 1152.89 toks/s]\n",
      " 35%|███▍      | 48/139 [24:43<42:00, 27.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:28:08 scheduler.py:1754] Sequence group 11565 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.87it/s, est. speed input: 1605.93 toks/s, output: 1131.30 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.64it/s, est. speed input: 1559.60 toks/s, output: 1081.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.48it/s, est. speed input: 1730.83 toks/s, output: 1125.61 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.46it/s, est. speed input: 1521.39 toks/s, output: 1128.92 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:28:32 scheduler.py:1754] Sequence group 11749 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.29it/s, est. speed input: 1894.29 toks/s, output: 1059.93 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.80it/s, est. speed input: 1414.51 toks/s, output: 1194.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.56it/s, est. speed input: 1780.18 toks/s, output: 1107.79 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:28:50 scheduler.py:1754] Sequence group 11893 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=2951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.23it/s, est. speed input: 1504.90 toks/s, output: 1124.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.36it/s, est. speed input: 1322.62 toks/s, output: 1082.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.06it/s, est. speed input: 1884.15 toks/s, output: 1067.57 toks/s]\n",
      " 36%|███▌      | 50/139 [25:45<43:41, 29.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:29:09 scheduler.py:1754] Sequence group 12040 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.89it/s, est. speed input: 1657.89 toks/s, output: 1165.29 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.82it/s, est. speed input: 1649.37 toks/s, output: 1109.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.03it/s, est. speed input: 1483.33 toks/s, output: 1107.59 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.53it/s, est. speed input: 1590.17 toks/s, output: 1127.56 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:29:35 scheduler.py:1754] Sequence group 12229 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.25it/s, est. speed input: 1318.87 toks/s, output: 1050.67 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.25it/s, est. speed input: 1470.87 toks/s, output: 1192.97 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.17it/s, est. speed input: 1880.98 toks/s, output: 1030.00 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.27it/s, est. speed input: 1695.87 toks/s, output: 1100.03 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:29:59 scheduler.py:1754] Sequence group 12418 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.79it/s, est. speed input: 2008.74 toks/s, output: 1045.07 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.19it/s, est. speed input: 1681.09 toks/s, output: 1078.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.07it/s, est. speed input: 1201.59 toks/s, output: 1138.38 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.73it/s, est. speed input: 1926.02 toks/s, output: 1052.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:30:23 scheduler.py:1754] Sequence group 12619 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.17it/s, est. speed input: 2014.53 toks/s, output: 964.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.18it/s, est. speed input: 1818.31 toks/s, output: 977.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.83it/s, est. speed input: 1748.40 toks/s, output: 1055.40 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.09it/s, est. speed input: 1293.32 toks/s, output: 1131.44 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:30:48 scheduler.py:1754] Sequence group 12797 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.15it/s, est. speed input: 1307.02 toks/s, output: 1127.78 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.39it/s, est. speed input: 1368.35 toks/s, output: 1051.07 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:31:08 scheduler.py:1754] Sequence group 12889 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:10<00:00,  4.63it/s, est. speed input: 1175.40 toks/s, output: 1160.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:10<00:00,  4.75it/s, est. speed input: 1206.07 toks/s, output: 1138.31 toks/s]\n",
      " 39%|███▉      | 54/139 [28:03<49:40, 35.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:31:30 scheduler.py:1754] Sequence group 12988 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.41it/s, est. speed input: 1377.79 toks/s, output: 1049.49 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.16it/s, est. speed input: 1323.81 toks/s, output: 1007.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.71it/s, est. speed input: 1657.01 toks/s, output: 1076.09 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.41it/s, est. speed input: 1377.92 toks/s, output: 1099.93 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:31:55 scheduler.py:1754] Sequence group 13181 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.24it/s, est. speed input: 1773.03 toks/s, output: 1078.25 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.11it/s, est. speed input: 1598.85 toks/s, output: 1121.36 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.14it/s, est. speed input: 1823.37 toks/s, output: 1142.65 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.75it/s, est. speed input: 1746.47 toks/s, output: 1001.99 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:32:18 scheduler.py:1754] Sequence group 13377 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.51it/s, est. speed input: 1698.46 toks/s, output: 1000.87 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.36it/s, est. speed input: 1668.43 toks/s, output: 997.47 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.40it/s, est. speed input: 1823.51 toks/s, output: 1079.77 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.01it/s, est. speed input: 1959.85 toks/s, output: 937.99 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.11it/s, est. speed input: 1978.80 toks/s, output: 894.82 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.19it/s, est. speed input: 1603.09 toks/s, output: 1144.55 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:32:51 scheduler.py:1754] Sequence group 13677 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  6.87it/s, est. speed input: 1344.29 toks/s, output: 1140.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.16it/s, est. speed input: 1823.57 toks/s, output: 1015.07 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.80it/s, est. speed input: 2149.37 toks/s, output: 847.41 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.97it/s, est. speed input: 1784.75 toks/s, output: 971.59 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.67it/s, est. speed input: 1924.50 toks/s, output: 870.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:33:18 scheduler.py:1754] Sequence group 13913 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.48it/s, est. speed input: 1488.79 toks/s, output: 1160.06 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.01it/s, est. speed input: 1233.49 toks/s, output: 1087.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.55it/s, est. speed input: 1612.22 toks/s, output: 1068.67 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:33:43 scheduler.py:1754] Sequence group 14047 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:10<00:00,  4.78it/s, est. speed input: 1175.27 toks/s, output: 1168.60 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  4.84it/s, est. speed input: 1190.08 toks/s, output: 1144.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  4.97it/s, est. speed input: 1223.79 toks/s, output: 1148.44 toks/s]\n",
      " 42%|████▏     | 59/139 [30:47<46:29, 34.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:34:09 scheduler.py:1754] Sequence group 14185 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.29it/s, est. speed input: 1823.27 toks/s, output: 1088.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.74it/s, est. speed input: 1262.28 toks/s, output: 1036.72 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:34:27 scheduler.py:1754] Sequence group 14302 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.75it/s, est. speed input: 1264.89 toks/s, output: 1022.93 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.13it/s, est. speed input: 1787.69 toks/s, output: 1135.76 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.85it/s, est. speed input: 1946.94 toks/s, output: 1122.07 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.44it/s, est. speed input: 1841.42 toks/s, output: 1045.63 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.26it/s, est. speed input: 1621.43 toks/s, output: 1035.81 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.94it/s, est. speed input: 1558.71 toks/s, output: 1099.97 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:35:00 scheduler.py:1754] Sequence group 14574 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.10it/s, est. speed input: 1786.65 toks/s, output: 982.06 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.43it/s, est. speed input: 1262.16 toks/s, output: 1131.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.60it/s, est. speed input: 1693.39 toks/s, output: 1056.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.77it/s, est. speed input: 1568.44 toks/s, output: 1104.25 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.08it/s, est. speed input: 2040.96 toks/s, output: 983.09 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:35:30 scheduler.py:1754] Sequence group 14819 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.09it/s, est. speed input: 1839.76 toks/s, output: 1152.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.97it/s, est. speed input: 1816.36 toks/s, output: 967.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.67it/s, est. speed input: 1313.72 toks/s, output: 1079.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.35it/s, est. speed input: 1644.86 toks/s, output: 1066.31 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:35:55 scheduler.py:1754] Sequence group 15022 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.01it/s, est. speed input: 1775.28 toks/s, output: 1008.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.71it/s, est. speed input: 1716.11 toks/s, output: 1036.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.85it/s, est. speed input: 1742.96 toks/s, output: 964.56 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.32it/s, est. speed input: 1714.48 toks/s, output: 1149.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.79it/s, est. speed input: 1815.43 toks/s, output: 1044.61 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.77it/s, est. speed input: 1822.77 toks/s, output: 1086.10 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:36:27 scheduler.py:1754] Sequence group 15302 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.20it/s, est. speed input: 1704.52 toks/s, output: 1041.26 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.73it/s, est. speed input: 2023.02 toks/s, output: 1043.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.74it/s, est. speed input: 1713.16 toks/s, output: 1125.72 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.72it/s, est. speed input: 1713.94 toks/s, output: 1159.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.57it/s, est. speed input: 1879.71 toks/s, output: 897.01 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:36:54 scheduler.py:1754] Sequence group 15542 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.87it/s, est. speed input: 1742.36 toks/s, output: 1051.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.83it/s, est. speed input: 1735.23 toks/s, output: 1065.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.66it/s, est. speed input: 1826.43 toks/s, output: 1052.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.58it/s, est. speed input: 1833.56 toks/s, output: 966.58 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.11it/s, est. speed input: 1567.87 toks/s, output: 1131.52 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:37:20 scheduler.py:1754] Sequence group 15771 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=3951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.69it/s, est. speed input: 1887.70 toks/s, output: 968.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.32it/s, est. speed input: 1621.74 toks/s, output: 1018.98 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.30it/s, est. speed input: 1669.08 toks/s, output: 1094.03 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.98it/s, est. speed input: 1638.57 toks/s, output: 1138.12 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:37:44 scheduler.py:1754] Sequence group 15975 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.25it/s, est. speed input: 1693.14 toks/s, output: 1120.68 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.62it/s, est. speed input: 1563.84 toks/s, output: 1156.05 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.89it/s, est. speed input: 1824.04 toks/s, output: 976.63 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.32it/s, est. speed input: 1464.08 toks/s, output: 1161.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.37it/s, est. speed input: 1893.35 toks/s, output: 992.35 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:38:13 scheduler.py:1754] Sequence group 16221 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.22it/s, est. speed input: 1661.15 toks/s, output: 1105.26 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.15it/s, est. speed input: 1850.42 toks/s, output: 1050.73 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.15it/s, est. speed input: 1849.34 toks/s, output: 1009.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.28it/s, est. speed input: 1704.81 toks/s, output: 1142.40 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.80it/s, est. speed input: 1825.47 toks/s, output: 1052.45 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:38:43 scheduler.py:1754] Sequence group 16462 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.70it/s, est. speed input: 1390.74 toks/s, output: 1103.54 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.20it/s, est. speed input: 1908.80 toks/s, output: 991.40 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.90it/s, est. speed input: 1639.58 toks/s, output: 1099.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.76it/s, est. speed input: 1913.78 toks/s, output: 878.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.02it/s, est. speed input: 1768.69 toks/s, output: 1156.38 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.31it/s, est. speed input: 1629.29 toks/s, output: 1171.22 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:39:16 scheduler.py:1754] Sequence group 16750 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.00it/s, est. speed input: 1960.58 toks/s, output: 995.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.15it/s, est. speed input: 1792.77 toks/s, output: 1112.86 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.08it/s, est. speed input: 1314.08 toks/s, output: 1059.58 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:39:36 scheduler.py:1754] Sequence group 16888 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.93it/s, est. speed input: 1281.74 toks/s, output: 1066.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.20it/s, est. speed input: 1770.88 toks/s, output: 1149.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.65it/s, est. speed input: 1435.76 toks/s, output: 1077.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.45it/s, est. speed input: 1609.55 toks/s, output: 1073.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.67it/s, est. speed input: 1682.39 toks/s, output: 974.89 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:40:06 scheduler.py:1754] Sequence group 17119 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.42it/s, est. speed input: 1648.80 toks/s, output: 955.60 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.52it/s, est. speed input: 1668.25 toks/s, output: 1113.82 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.58it/s, est. speed input: 1877.06 toks/s, output: 1008.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.46it/s, est. speed input: 1853.55 toks/s, output: 982.38 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.21it/s, est. speed input: 1560.48 toks/s, output: 1183.88 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.95it/s, est. speed input: 1891.69 toks/s, output: 930.70 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:40:37 scheduler.py:1754] Sequence group 17404 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.84it/s, est. speed input: 1679.84 toks/s, output: 1064.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.01it/s, est. speed input: 1712.78 toks/s, output: 1122.50 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.96it/s, est. speed input: 1703.65 toks/s, output: 997.53 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.23it/s, est. speed input: 1453.16 toks/s, output: 1156.89 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:41:00 scheduler.py:1754] Sequence group 17597 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.41it/s, est. speed input: 1891.79 toks/s, output: 1105.11 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.75it/s, est. speed input: 1357.25 toks/s, output: 1160.58 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.14it/s, est. speed input: 1838.14 toks/s, output: 1083.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:41:17 scheduler.py:1754] Sequence group 17741 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.54it/s, est. speed input: 1916.69 toks/s, output: 1037.81 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.59it/s, est. speed input: 1760.60 toks/s, output: 1073.89 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.79it/s, est. speed input: 1601.84 toks/s, output: 1056.79 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.69it/s, est. speed input: 1385.94 toks/s, output: 1104.26 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:41:43 scheduler.py:1754] Sequence group 17939 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.81it/s, est. speed input: 1632.19 toks/s, output: 1121.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.74it/s, est. speed input: 1829.78 toks/s, output: 1010.31 toks/s]\n",
      " 54%|█████▍    | 75/139 [38:31<31:15, 29.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:00<00:00, 2632.99it/s, est. speed input: 5449237.63 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:00<00:00, 2144.88it/s, est. speed input: 4413091.99 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:00<00:00, 2312.64it/s, est. speed input: 4759477.43 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:00<00:00, 1985.43it/s, est. speed input: 4084257.61 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:41:53 scheduler.py:1091] Input prompt (2049 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:00<00:00, 2341.85it/s, est. speed input: 4819982.32 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.79it/s, est. speed input: 1784.25 toks/s, output: 1034.77 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.50it/s, est. speed input: 1522.74 toks/s, output: 1129.08 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:42:06 scheduler.py:1754] Sequence group 18375 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.76it/s, est. speed input: 1575.48 toks/s, output: 1142.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.80it/s, est. speed input: 1787.14 toks/s, output: 956.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.59it/s, est. speed input: 1540.06 toks/s, output: 1137.02 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.44it/s, est. speed input: 1860.58 toks/s, output: 1094.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:42:29 scheduler.py:1754] Sequence group 18562 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.79it/s, est. speed input: 1535.14 toks/s, output: 1110.28 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.99it/s, est. speed input: 1772.33 toks/s, output: 1076.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.87it/s, est. speed input: 1551.31 toks/s, output: 1141.00 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.21it/s, est. speed input: 1813.86 toks/s, output: 1118.12 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.80it/s, est. speed input: 2051.17 toks/s, output: 860.72 toks/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:42:57 scheduler.py:1754] Sequence group 18804 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.76it/s, est. speed input: 1679.46 toks/s, output: 1071.63 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.64it/s, est. speed input: 2045.52 toks/s, output: 820.38 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.63it/s, est. speed input: 1855.61 toks/s, output: 1066.10 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.12it/s, est. speed input: 1758.46 toks/s, output: 1019.41 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.20it/s, est. speed input: 1840.22 toks/s, output: 949.25 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.16it/s, est. speed input: 1633.01 toks/s, output: 1087.31 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:43:27 scheduler.py:1754] Sequence group 19084 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.71it/s, est. speed input: 1541.80 toks/s, output: 1125.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.11it/s, est. speed input: 1823.42 toks/s, output: 970.97 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.69it/s, est. speed input: 1738.92 toks/s, output: 1013.82 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.77it/s, est. speed input: 1914.38 toks/s, output: 1049.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.08it/s, est. speed input: 1976.08 toks/s, output: 925.86 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:43:54 scheduler.py:1754] Sequence group 19333 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.26it/s, est. speed input: 1814.87 toks/s, output: 1060.79 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.99it/s, est. speed input: 1957.63 toks/s, output: 842.31 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.59it/s, est. speed input: 1880.34 toks/s, output: 1009.52 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.51it/s, est. speed input: 1240.57 toks/s, output: 994.18 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:44:21 scheduler.py:1754] Sequence group 19529 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.12it/s, est. speed input: 1376.43 toks/s, output: 1027.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  6.91it/s, est. speed input: 1554.09 toks/s, output: 1100.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.50it/s, est. speed input: 1462.82 toks/s, output: 1045.37 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  6.86it/s, est. speed input: 1543.89 toks/s, output: 1047.84 toks/s]\n",
      " 59%|█████▉    | 82/139 [41:24<27:43, 29.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:44:48 scheduler.py:1754] Sequence group 19718 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.18it/s, est. speed input: 1701.77 toks/s, output: 1090.37 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  6.96it/s, est. speed input: 1447.18 toks/s, output: 1160.03 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.10it/s, est. speed input: 1685.70 toks/s, output: 1035.83 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:45:06 scheduler.py:1754] Sequence group 19857 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.08it/s, est. speed input: 1681.57 toks/s, output: 1144.29 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  6.95it/s, est. speed input: 1445.86 toks/s, output: 1123.06 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.55it/s, est. speed input: 1861.81 toks/s, output: 1057.01 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.13it/s, est. speed input: 1584.73 toks/s, output: 1164.68 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:45:29 scheduler.py:1754] Sequence group 20044 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.02it/s, est. speed input: 1758.57 toks/s, output: 956.31 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:03<00:00, 14.27it/s, est. speed input: 2784.53 toks/s, output: 935.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.70it/s, est. speed input: 1891.61 toks/s, output: 995.32 toks/s]\n",
      " 60%|██████    | 84/139 [42:20<25:57, 28.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:00<00:00, 2457.18it/s, est. speed input: 3735077.39 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:00<00:00, 2388.41it/s, est. speed input: 3631525.49 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:00<00:00, 2308.08it/s, est. speed input: 3509354.11 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:00<00:00, 2496.05it/s, est. speed input: 3797810.34 toks/s, output: 0.00 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n",
      "WARNING 05-09 19:45:43 scheduler.py:1091] Input prompt (1514 tokens) is too long and exceeds limit of 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:00<00:00, 2250.79it/s, est. speed input: 3421047.16 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.60it/s, est. speed input: 1872.33 toks/s, output: 934.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.66it/s, est. speed input: 1716.69 toks/s, output: 1002.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.10it/s, est. speed input: 1605.23 toks/s, output: 1042.42 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:46:01 scheduler.py:1754] Sequence group 20586 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=4951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.05it/s, est. speed input: 1992.82 toks/s, output: 1041.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.35it/s, est. speed input: 1456.66 toks/s, output: 1153.54 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.85it/s, est. speed input: 1648.38 toks/s, output: 1076.68 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.94it/s, est. speed input: 1876.83 toks/s, output: 952.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.11it/s, est. speed input: 1703.69 toks/s, output: 1096.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.50it/s, est. speed input: 1784.96 toks/s, output: 1059.47 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:46:34 scheduler.py:1754] Sequence group 20861 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.67it/s, est. speed input: 1819.98 toks/s, output: 1083.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.15it/s, est. speed input: 1831.06 toks/s, output: 1061.44 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.11it/s, est. speed input: 2022.83 toks/s, output: 856.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.28it/s, est. speed input: 1856.44 toks/s, output: 1064.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.59it/s, est. speed input: 1518.63 toks/s, output: 1061.14 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:47:01 scheduler.py:1754] Sequence group 21103 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.27it/s, est. speed input: 1654.18 toks/s, output: 1132.59 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.89it/s, est. speed input: 1761.16 toks/s, output: 1012.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.11it/s, est. speed input: 1606.80 toks/s, output: 1086.58 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.16it/s, est. speed input: 1812.95 toks/s, output: 1085.02 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.08it/s, est. speed input: 1797.35 toks/s, output: 990.39 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:47:29 scheduler.py:1754] Sequence group 21345 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.45it/s, est. speed input: 1672.82 toks/s, output: 1068.74 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:11<00:00,  4.15it/s, est. speed input: 1729.11 toks/s, output: 969.68 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:10<00:00,  4.71it/s, est. speed input: 1963.55 toks/s, output: 990.41 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:48:01 scheduler.py:1754] Sequence group 21480 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:11<00:00,  4.26it/s, est. speed input: 1775.89 toks/s, output: 1001.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:11<00:00,  4.17it/s, est. speed input: 1737.78 toks/s, output: 980.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:11<00:00,  4.14it/s, est. speed input: 1726.37 toks/s, output: 988.85 toks/s]\n",
      " 65%|██████▍   | 90/139 [45:08<28:32, 34.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:48:32 scheduler.py:1754] Sequence group 21638 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.13it/s, est. speed input: 1490.41 toks/s, output: 1110.82 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.16it/s, est. speed input: 1706.33 toks/s, output: 1083.12 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.33it/s, est. speed input: 1741.13 toks/s, output: 1035.09 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.89it/s, est. speed input: 1649.87 toks/s, output: 1120.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:48:57 scheduler.py:1754] Sequence group 21831 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.68it/s, est. speed input: 1187.95 toks/s, output: 974.56 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 11.24it/s, est. speed input: 2303.38 toks/s, output: 809.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.90it/s, est. speed input: 1845.23 toks/s, output: 1005.85 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.70it/s, est. speed input: 1825.66 toks/s, output: 985.21 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:49:21 scheduler.py:1754] Sequence group 22020 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.17it/s, est. speed input: 1513.73 toks/s, output: 1083.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.74it/s, est. speed input: 1844.87 toks/s, output: 986.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.02it/s, est. speed input: 1731.72 toks/s, output: 1019.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.16it/s, est. speed input: 1567.09 toks/s, output: 1143.01 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:49:42 scheduler.py:1754] Sequence group 22205 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.44it/s, est. speed input: 2005.04 toks/s, output: 900.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.46it/s, est. speed input: 1816.60 toks/s, output: 976.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.94it/s, est. speed input: 1909.44 toks/s, output: 992.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.18it/s, est. speed input: 1774.31 toks/s, output: 1073.51 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:50:05 scheduler.py:1754] Sequence group 22406 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.45it/s, est. speed input: 1182.22 toks/s, output: 1034.78 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.70it/s, est. speed input: 1236.49 toks/s, output: 1038.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.53it/s, est. speed input: 1852.27 toks/s, output: 1032.12 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:50:27 scheduler.py:1754] Sequence group 22548 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.85it/s, est. speed input: 1269.17 toks/s, output: 1091.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.92it/s, est. speed input: 1672.22 toks/s, output: 1130.83 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.02it/s, est. speed input: 1691.81 toks/s, output: 1142.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.85it/s, est. speed input: 1867.84 toks/s, output: 1105.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.56it/s, est. speed input: 1805.98 toks/s, output: 1016.39 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:50:57 scheduler.py:1754] Sequence group 22786 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.83it/s, est. speed input: 1863.38 toks/s, output: 1052.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.95it/s, est. speed input: 1558.82 toks/s, output: 1130.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.31it/s, est. speed input: 1643.81 toks/s, output: 1040.09 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.46it/s, est. speed input: 1870.05 toks/s, output: 944.58 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.52it/s, est. speed input: 1883.00 toks/s, output: 964.82 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:51:26 scheduler.py:1754] Sequence group 23029 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.48it/s, est. speed input: 1675.98 toks/s, output: 968.07 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:11<00:00,  4.08it/s, est. speed input: 1118.14 toks/s, output: 1037.04 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:51:48 scheduler.py:1754] Sequence group 23135 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  4.92it/s, est. speed input: 1347.87 toks/s, output: 1088.79 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:10<00:00,  4.46it/s, est. speed input: 1221.06 toks/s, output: 1117.35 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:52:10 scheduler.py:1754] Sequence group 23229 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:11<00:00,  4.00it/s, est. speed input: 1096.57 toks/s, output: 1026.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:10<00:00,  4.47it/s, est. speed input: 1225.55 toks/s, output: 1124.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.42it/s, est. speed input: 1959.18 toks/s, output: 947.02 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:52:31 scheduler.py:1754] Sequence group 23370 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.79it/s, est. speed input: 1513.03 toks/s, output: 1174.78 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.98it/s, est. speed input: 1937.57 toks/s, output: 1028.85 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.68it/s, est. speed input: 1879.95 toks/s, output: 1034.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.46it/s, est. speed input: 1837.65 toks/s, output: 985.26 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.58it/s, est. speed input: 1887.24 toks/s, output: 998.50 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:52:56 scheduler.py:1754] Sequence group 23604 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.50it/s, est. speed input: 1881.72 toks/s, output: 965.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.56it/s, est. speed input: 1710.57 toks/s, output: 1070.58 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.56it/s, est. speed input: 1910.98 toks/s, output: 955.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.89it/s, est. speed input: 1775.36 toks/s, output: 1056.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  6.90it/s, est. speed input: 1490.90 toks/s, output: 1098.19 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:53:25 scheduler.py:1754] Sequence group 23842 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.27it/s, est. speed input: 1137.56 toks/s, output: 977.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.90it/s, est. speed input: 1707.39 toks/s, output: 1034.35 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:53:44 scheduler.py:1754] Sequence group 23946 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.79it/s, est. speed input: 1251.30 toks/s, output: 1033.82 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.32it/s, est. speed input: 1364.50 toks/s, output: 1066.81 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.77it/s, est. speed input: 1577.34 toks/s, output: 1118.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.27it/s, est. speed input: 1882.57 toks/s, output: 995.19 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:54:08 scheduler.py:1754] Sequence group 24142 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.15it/s, est. speed input: 1654.58 toks/s, output: 1169.11 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.95it/s, est. speed input: 1816.28 toks/s, output: 1162.20 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.33it/s, est. speed input: 2096.24 toks/s, output: 934.31 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.11it/s, est. speed input: 1458.70 toks/s, output: 1135.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.72it/s, est. speed input: 1787.80 toks/s, output: 1148.62 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:54:35 scheduler.py:1754] Sequence group 24371 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=5951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.97it/s, est. speed input: 2044.11 toks/s, output: 1032.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.39it/s, est. speed input: 1514.25 toks/s, output: 1168.31 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.36it/s, est. speed input: 1713.60 toks/s, output: 1138.04 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.25it/s, est. speed input: 1767.71 toks/s, output: 1018.63 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:54:58 scheduler.py:1754] Sequence group 24565 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.74it/s, est. speed input: 1749.95 toks/s, output: 1080.93 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.07it/s, est. speed input: 2024.63 toks/s, output: 1044.52 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.41it/s, est. speed input: 2092.61 toks/s, output: 878.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.77it/s, est. speed input: 1763.17 toks/s, output: 1046.49 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.73it/s, est. speed input: 1907.44 toks/s, output: 1034.61 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.03it/s, est. speed input: 1574.66 toks/s, output: 1069.85 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:55:29 scheduler.py:1754] Sequence group 24852 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.85it/s, est. speed input: 1735.52 toks/s, output: 1056.65 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.79it/s, est. speed input: 1331.82 toks/s, output: 1070.49 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.73it/s, est. speed input: 1908.16 toks/s, output: 959.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.27it/s, est. speed input: 1304.50 toks/s, output: 1076.63 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:55:55 scheduler.py:1754] Sequence group 25039 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.38it/s, est. speed input: 1386.35 toks/s, output: 1096.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.75it/s, est. speed input: 1684.81 toks/s, output: 1129.61 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.13it/s, est. speed input: 1549.97 toks/s, output: 1120.47 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:56:14 scheduler.py:1754] Sequence group 25179 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.71it/s, est. speed input: 1893.64 toks/s, output: 1034.03 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.42it/s, est. speed input: 1607.81 toks/s, output: 1127.47 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.40it/s, est. speed input: 1604.75 toks/s, output: 1065.28 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.38it/s, est. speed input: 1601.23 toks/s, output: 1091.41 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:56:37 scheduler.py:1754] Sequence group 25377 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.51it/s, est. speed input: 1625.12 toks/s, output: 1069.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.36it/s, est. speed input: 1597.50 toks/s, output: 1079.98 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.19it/s, est. speed input: 1115.67 toks/s, output: 1106.37 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:56:58 scheduler.py:1754] Sequence group 25524 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.62it/s, est. speed input: 1423.62 toks/s, output: 1154.76 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.96it/s, est. speed input: 1281.98 toks/s, output: 1096.51 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:57:14 scheduler.py:1754] Sequence group 25620 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.35it/s, est. speed input: 1796.31 toks/s, output: 1043.67 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.66it/s, est. speed input: 1647.11 toks/s, output: 1127.28 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.36it/s, est. speed input: 1698.42 toks/s, output: 1024.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.82it/s, est. speed input: 1789.75 toks/s, output: 1100.41 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.30it/s, est. speed input: 1483.08 toks/s, output: 1116.12 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.54it/s, est. speed input: 1935.79 toks/s, output: 1089.87 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:57:48 scheduler.py:1754] Sequence group 25903 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.59it/s, est. speed input: 1744.10 toks/s, output: 1100.44 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.49it/s, est. speed input: 1952.01 toks/s, output: 904.07 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.12it/s, est. speed input: 1725.61 toks/s, output: 1019.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.76it/s, est. speed input: 1657.46 toks/s, output: 1105.34 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.08it/s, est. speed input: 1908.07 toks/s, output: 1034.69 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:58:13 scheduler.py:1754] Sequence group 26140 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.78it/s, est. speed input: 1471.84 toks/s, output: 1053.97 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.60it/s, est. speed input: 1565.04 toks/s, output: 1154.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.60it/s, est. speed input: 1566.67 toks/s, output: 1095.62 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:58:33 scheduler.py:1754] Sequence group 26293 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.35it/s, est. speed input: 1307.72 toks/s, output: 1105.11 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.44it/s, est. speed input: 1327.70 toks/s, output: 1142.67 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.61it/s, est. speed input: 1980.09 toks/s, output: 1055.52 toks/s]\n",
      " 79%|███████▉  | 110/139 [55:29<14:43, 30.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:58:54 scheduler.py:1754] Sequence group 26441 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.94it/s, est. speed input: 1723.41 toks/s, output: 1095.17 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.88it/s, est. speed input: 1276.88 toks/s, output: 1037.46 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.58it/s, est. speed input: 1645.23 toks/s, output: 1137.88 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:59:14 scheduler.py:1754] Sequence group 26577 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.53it/s, est. speed input: 1633.54 toks/s, output: 1162.42 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.22it/s, est. speed input: 1784.82 toks/s, output: 1160.41 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  4.98it/s, est. speed input: 1359.20 toks/s, output: 1151.03 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:59:36 scheduler.py:1754] Sequence group 26707 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:11<00:00,  4.21it/s, est. speed input: 1150.18 toks/s, output: 1086.10 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.14it/s, est. speed input: 1402.95 toks/s, output: 1113.99 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 19:59:58 scheduler.py:1754] Sequence group 26811 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:12<00:00,  3.87it/s, est. speed input: 1057.54 toks/s, output: 1054.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:13<00:00,  3.69it/s, est. speed input: 1006.35 toks/s, output: 1124.31 toks/s]\n",
      " 81%|████████  | 112/139 [56:58<17:21, 38.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:00:21 scheduler.py:1754] Sequence group 26907 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.69it/s, est. speed input: 1764.05 toks/s, output: 1092.93 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.43it/s, est. speed input: 1915.18 toks/s, output: 1045.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.51it/s, est. speed input: 1930.49 toks/s, output: 878.27 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.84it/s, est. speed input: 1795.36 toks/s, output: 1102.38 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.06it/s, est. speed input: 1840.12 toks/s, output: 1037.52 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.98it/s, est. speed input: 1684.78 toks/s, output: 1153.46 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:00:53 scheduler.py:1754] Sequence group 27196 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.18it/s, est. speed input: 1726.07 toks/s, output: 1026.47 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.80it/s, est. speed input: 1645.06 toks/s, output: 1135.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.86it/s, est. speed input: 1870.45 toks/s, output: 1037.17 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.05it/s, est. speed input: 1698.38 toks/s, output: 1056.79 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.25it/s, est. speed input: 2039.43 toks/s, output: 904.63 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.29it/s, est. speed input: 2048.00 toks/s, output: 862.98 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:01:26 scheduler.py:1754] Sequence group 27484 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.23it/s, est. speed input: 2035.35 toks/s, output: 884.28 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.09it/s, est. speed input: 1808.97 toks/s, output: 995.01 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.64it/s, est. speed input: 1720.49 toks/s, output: 1102.86 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.60it/s, est. speed input: 1551.09 toks/s, output: 1112.94 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:01:49 scheduler.py:1754] Sequence group 27683 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.25it/s, est. speed input: 1071.07 toks/s, output: 1110.11 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.94it/s, est. speed input: 1825.13 toks/s, output: 880.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.26it/s, est. speed input: 1889.52 toks/s, output: 1121.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.76it/s, est. speed input: 1786.23 toks/s, output: 1018.61 toks/s]\n",
      " 83%|████████▎ | 116/139 [58:50<11:52, 30.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:02:13 scheduler.py:1754] Sequence group 27867 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.44it/s, est. speed input: 1756.42 toks/s, output: 1018.25 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.23it/s, est. speed input: 1920.17 toks/s, output: 1045.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s, est. speed input: 1296.57 toks/s, output: 1086.83 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:02:33 scheduler.py:1754] Sequence group 28021 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=6951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.62it/s, est. speed input: 1793.38 toks/s, output: 948.60 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.02it/s, est. speed input: 1669.08 toks/s, output: 1026.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.12it/s, est. speed input: 1587.92 toks/s, output: 1114.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.22it/s, est. speed input: 1609.83 toks/s, output: 1087.21 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:02:58 scheduler.py:1754] Sequence group 28205 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:09<00:00,  5.26it/s, est. speed input: 1173.87 toks/s, output: 1044.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.41it/s, est. speed input: 1430.42 toks/s, output: 1070.54 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.66it/s, est. speed input: 1707.47 toks/s, output: 1088.06 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.47it/s, est. speed input: 1884.45 toks/s, output: 1022.91 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:03:25 scheduler.py:1754] Sequence group 28398 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.94it/s, est. speed input: 1784.32 toks/s, output: 1067.13 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.43it/s, est. speed input: 1696.17 toks/s, output: 1108.65 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.35it/s, est. speed input: 1880.95 toks/s, output: 957.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.27it/s, est. speed input: 2066.17 toks/s, output: 854.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.56it/s, est. speed input: 1728.67 toks/s, output: 1097.18 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:03:53 scheduler.py:1754] Sequence group 28647 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.66it/s, est. speed input: 1548.35 toks/s, output: 1173.07 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.20it/s, est. speed input: 1656.86 toks/s, output: 1137.21 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.74it/s, est. speed input: 1563.17 toks/s, output: 1144.97 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.91it/s, est. speed input: 1597.46 toks/s, output: 1105.34 toks/s]\n",
      " 86%|████████▋ | 120/139 [1:00:53<09:36, 30.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:04:17 scheduler.py:1754] Sequence group 28843 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.45it/s, est. speed input: 1765.45 toks/s, output: 1073.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.85it/s, est. speed input: 1850.04 toks/s, output: 991.78 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.84it/s, est. speed input: 1638.46 toks/s, output: 1130.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.18it/s, est. speed input: 1292.18 toks/s, output: 1085.06 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:04:41 scheduler.py:1754] Sequence group 29029 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.83it/s, est. speed input: 2053.98 toks/s, output: 981.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.48it/s, est. speed input: 1628.81 toks/s, output: 1061.83 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.72it/s, est. speed input: 1673.61 toks/s, output: 1184.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.42it/s, est. speed input: 1425.02 toks/s, output: 1137.42 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:05:03 scheduler.py:1754] Sequence group 29213 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.61it/s, est. speed input: 2036.40 toks/s, output: 907.93 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.99it/s, est. speed input: 2110.78 toks/s, output: 855.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.68it/s, est. speed input: 1876.99 toks/s, output: 1043.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.18it/s, est. speed input: 1987.08 toks/s, output: 886.96 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.74it/s, est. speed input: 1900.96 toks/s, output: 1027.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.47it/s, est. speed input: 2044.22 toks/s, output: 930.14 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:05:33 scheduler.py:1754] Sequence group 29516 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.84it/s, est. speed input: 1726.77 toks/s, output: 1078.56 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.91it/s, est. speed input: 1574.76 toks/s, output: 1160.63 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.79it/s, est. speed input: 1550.50 toks/s, output: 1105.09 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.09it/s, est. speed input: 1609.99 toks/s, output: 1116.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.79it/s, est. speed input: 1750.66 toks/s, output: 1067.59 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:06:02 scheduler.py:1754] Sequence group 29751 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.04it/s, est. speed input: 1600.99 toks/s, output: 1055.26 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.63it/s, est. speed input: 1683.24 toks/s, output: 1061.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.84it/s, est. speed input: 2114.70 toks/s, output: 934.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.32it/s, est. speed input: 1623.06 toks/s, output: 1037.47 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.95it/s, est. speed input: 1550.01 toks/s, output: 1135.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.45it/s, est. speed input: 2038.57 toks/s, output: 957.65 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:02<00:00, 22.82it/s, est. speed input: 17027.58 toks/s, output: 494.54 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:02<00:00, 22.95it/s, est. speed input: 17119.01 toks/s, output: 496.72 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:02<00:00, 23.58it/s, est. speed input: 17593.23 toks/s, output: 499.67 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:02<00:00, 22.61it/s, est. speed input: 16868.03 toks/s, output: 495.09 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:02<00:00, 23.47it/s, est. speed input: 17513.68 toks/s, output: 493.50 toks/s]\n",
      " 91%|█████████ | 126/139 [1:03:21<04:53, 22.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:06:43 scheduler.py:1754] Sequence group 30267 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.44it/s, est. speed input: 1714.63 toks/s, output: 1018.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.60it/s, est. speed input: 1557.62 toks/s, output: 1164.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.33it/s, est. speed input: 1297.35 toks/s, output: 1100.28 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:07:03 scheduler.py:1754] Sequence group 30412 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.73it/s, est. speed input: 1789.77 toks/s, output: 1110.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.77it/s, est. speed input: 1592.62 toks/s, output: 1141.30 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.91it/s, est. speed input: 1205.97 toks/s, output: 1042.29 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:07:24 scheduler.py:1754] Sequence group 30561 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.07it/s, est. speed input: 1442.53 toks/s, output: 1117.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.32it/s, est. speed input: 1697.48 toks/s, output: 1007.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.14it/s, est. speed input: 1661.05 toks/s, output: 1044.60 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.21it/s, est. speed input: 1675.89 toks/s, output: 1079.26 toks/s]\n",
      " 92%|█████████▏| 128/139 [1:04:24<05:01, 27.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:07:49 scheduler.py:1754] Sequence group 30759 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.58it/s, est. speed input: 1606.62 toks/s, output: 1133.60 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.21it/s, est. speed input: 1542.89 toks/s, output: 1140.93 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.57it/s, est. speed input: 1404.74 toks/s, output: 1123.46 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:08:08 scheduler.py:1754] Sequence group 30897 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.96it/s, est. speed input: 1274.50 toks/s, output: 1045.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.72it/s, est. speed input: 1651.92 toks/s, output: 1116.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.71it/s, est. speed input: 1503.54 toks/s, output: 1160.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.54it/s, est. speed input: 1666.10 toks/s, output: 1055.37 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:08:33 scheduler.py:1754] Sequence group 31083 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.91it/s, est. speed input: 1542.40 toks/s, output: 1105.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.40it/s, est. speed input: 1637.90 toks/s, output: 982.04 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.34it/s, est. speed input: 1431.19 toks/s, output: 1101.67 toks/s]\n",
      " 94%|█████████▎| 130/139 [1:05:29<04:27, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:08:53 scheduler.py:1754] Sequence group 31241 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.64it/s, est. speed input: 1737.13 toks/s, output: 1025.21 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.56it/s, est. speed input: 1720.65 toks/s, output: 1161.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.77it/s, est. speed input: 1762.74 toks/s, output: 1118.34 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.29it/s, est. speed input: 1665.32 toks/s, output: 1106.93 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.58it/s, est. speed input: 1723.85 toks/s, output: 1150.84 toks/s]\n",
      " 94%|█████████▍| 131/139 [1:05:57<03:53, 29.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:09:20 scheduler.py:1754] Sequence group 31472 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.43it/s, est. speed input: 1913.99 toks/s, output: 967.99 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.99it/s, est. speed input: 1640.15 toks/s, output: 1102.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.35it/s, est. speed input: 1714.27 toks/s, output: 1105.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.34it/s, est. speed input: 1711.23 toks/s, output: 1030.77 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.53it/s, est. speed input: 1751.39 toks/s, output: 1007.14 toks/s]\n",
      " 95%|█████████▍| 132/139 [1:06:25<03:22, 28.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:09:48 scheduler.py:1754] Sequence group 31710 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.76it/s, est. speed input: 1835.04 toks/s, output: 940.29 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.61it/s, est. speed input: 1807.16 toks/s, output: 878.74 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 11.55it/s, est. speed input: 2172.84 toks/s, output: 867.06 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.66it/s, est. speed input: 1439.81 toks/s, output: 1118.62 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:10:09 scheduler.py:1754] Sequence group 31908 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00, 10.10it/s, est. speed input: 1900.10 toks/s, output: 964.37 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.26it/s, est. speed input: 1898.44 toks/s, output: 971.40 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.07it/s, est. speed input: 1654.34 toks/s, output: 1066.74 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.42it/s, est. speed input: 1725.63 toks/s, output: 1076.59 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:10:33 scheduler.py:1754] Sequence group 32108 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.06it/s, est. speed input: 1243.17 toks/s, output: 1074.88 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.49it/s, est. speed input: 1534.85 toks/s, output: 1153.78 toks/s]\n",
      " 96%|█████████▋| 134/139 [1:07:22<02:24, 28.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:10:52 scheduler.py:1754] Sequence group 32192 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=7951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:13<00:00,  3.65it/s, est. speed input: 1127.83 toks/s, output: 1138.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:11<00:00,  4.15it/s, est. speed input: 1281.29 toks/s, output: 1058.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:08<00:00,  5.59it/s, est. speed input: 1727.67 toks/s, output: 1076.30 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:11:22 scheduler.py:1754] Sequence group 32316 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:12<00:00,  3.75it/s, est. speed input: 1160.30 toks/s, output: 1104.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:11<00:00,  4.10it/s, est. speed input: 1267.41 toks/s, output: 1026.44 toks/s]\n",
      " 97%|█████████▋| 135/139 [1:08:20<02:30, 37.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:11:44 scheduler.py:1754] Sequence group 32442 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.48it/s, est. speed input: 1518.38 toks/s, output: 1130.05 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.35it/s, est. speed input: 1898.07 toks/s, output: 1035.52 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.23it/s, est. speed input: 1671.00 toks/s, output: 1122.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.47it/s, est. speed input: 1923.48 toks/s, output: 991.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.80it/s, est. speed input: 1584.08 toks/s, output: 1211.96 toks/s]\n",
      " 98%|█████████▊| 136/139 [1:08:48<01:44, 34.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:12:11 scheduler.py:1754] Sequence group 32671 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.05it/s, est. speed input: 1651.19 toks/s, output: 1110.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.05it/s, est. speed input: 1873.44 toks/s, output: 1035.31 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.41it/s, est. speed input: 1550.32 toks/s, output: 1162.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.63it/s, est. speed input: 1804.49 toks/s, output: 1083.52 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  8.31it/s, est. speed input: 1736.80 toks/s, output: 1096.18 toks/s]\n",
      " 99%|█████████▊| 137/139 [1:09:17<01:06, 33.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:12:40 scheduler.py:1754] Sequence group 32907 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.57it/s, est. speed input: 1846.73 toks/s, output: 1017.65 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:07<00:00,  6.81it/s, est. speed input: 1328.98 toks/s, output: 1107.53 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:06<00:00,  7.15it/s, est. speed input: 1393.87 toks/s, output: 1133.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 48/48 [00:04<00:00,  9.69it/s, est. speed input: 1890.75 toks/s, output: 953.86 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-09 20:13:05 scheduler.py:1754] Sequence group 33111 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=8201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 48/48 [00:05<00:00,  9.40it/s, est. speed input: 1832.74 toks/s, output: 964.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 11/11 [00:02<00:00,  4.15it/s, est. speed input: 731.48 toks/s, output: 377.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 11/11 [00:02<00:00,  4.57it/s, est. speed input: 840.12 toks/s, output: 469.04 toks/s] \n",
      "Processed prompts: 100%|██████████| 11/11 [00:02<00:00,  3.89it/s, est. speed input: 727.06 toks/s, output: 449.05 toks/s]\n",
      "Processed prompts: 100%|██████████| 11/11 [00:01<00:00,  7.75it/s, est. speed input: 1446.71 toks/s, output: 522.17 toks/s]\n",
      "Processed prompts: 100%|██████████| 11/11 [00:00<00:00, 20.11it/s, est. speed input: 3754.08 toks/s, output: 661.93 toks/s]\n",
      "100%|██████████| 139/139 [1:09:56<00:00, 30.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score: 0.2032\n",
      "Average tools used: 0.0104\n",
      "Average calls per sample: 1.2754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from pretrained peft model\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.lora.request import LoRARequest\n",
    "\n",
    "\n",
    "def load_model(model_name_or_path, peft_model_id):\n",
    "    # Load the base model\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, device_map=\"auto\", torch_dtype='auto')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "    # Load the PEFT model\n",
    "    peft_model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "    \n",
    "    return peft_model, tokenizer\n",
    "\n",
    "model, tokenizer = load_model(\"Qwen/Qwen2.5-0.5B-Instruct\", 'models/sft_base_qwen')\n",
    "vllm_lora_adapter = 'models/grpo_policy_model'\n",
    "base_model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "inference_engine = LLM(\n",
    "    model=base_model_name,\n",
    "    enable_lora=True,\n",
    "    max_lora_rank=64,\n",
    "    max_loras=1,\n",
    "    gpu_memory_utilization=0.2,\n",
    "    # enable_prefix_caching=True,\n",
    "    swap_space=6,\n",
    "    scheduling_policy=\"fcfs\",\n",
    "    dtype=torch.bfloat16,\n",
    "    max_model_len=768,\n",
    "    # enable_sleep_mode=True,\n",
    "    )\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=48, shuffle=True)\n",
    "\n",
    "# Evaluate the model\n",
    "avg_bleu, tools_used_avg, calls_per_sample_avg = evaluate_model(inference_engine, tokenizer, dataloader, actions_num=4, lora_request=LoRARequest('adapter', 1, vllm_lora_adapter), tools=TOOLS)\n",
    "print(f\"Average BLEU score: {avg_bleu:.4f}\")\n",
    "print(f\"Average tools used: {tools_used_avg:.4f}\")\n",
    "print(f\"Average calls per sample: {calls_per_sample_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db88073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
