{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6c8bb6-002a-4fef-97c1-aaa951a504cb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a1dd5d-2b6f-41db-bd5a-8e80c8ac2c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamosquerao/projects/rl_translator/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-19 15:31:24,603] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "os.environ[\"VLLM_ALLOW_LONG_MAX_MODEL_LEN\"] = \"1\"\n",
    "import torch\n",
    "import sacrebleu\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import evaluate\n",
    "import sacrebleu\n",
    "from transformers.tokenization_utils import AddedToken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3faaf64-5e2b-4295-b428-ea50c3683115",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9787ea-075f-4027-84a6-ba229ecd32bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPANISH_VAL_FILE = 'datasets/dev.es.txt'\n",
    "WAYUU_VAL_FILE = 'datasets/dev.guc.txt'\n",
    "MODEL_PATH = 'models/nllb_wayuu_esp_completo_1_3B-V2'\n",
    "TOKENIZER_PATH = 'models/nllb_wayuu_esp_completo_1_3B-V2' # Didnt save it oops\n",
    "SRC_LANG = \"spa_Latn\"\n",
    "TGT_LANG = \"way_Latn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f174013-1d41-42cb-85d7-94d9b04f29cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_PATH = \"nllb_original_evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e368344a-4cc9-430d-b186-3cc06e089f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306e458c-84d4-4c93-918e-29eb934569f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NEW_TOKENS = 512\n",
    "TEMPERATURE = 0.8\n",
    "TOP_P = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224caaf5-8265-45f9-a8c1-bfa7842136e4",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d962cc9f-d53a-49c4-bda2-26a12847c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, spa_path, wayuu_path):\n",
    "        with open(spa_path, 'r', encoding='utf-8') as f:\n",
    "            self.spa_lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "        with open(wayuu_path, 'r', encoding='utf-8') as f:\n",
    "            self.wayuu_lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.spa_lines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spa = self.spa_lines[idx]\n",
    "        wayuu = self.wayuu_lines[idx]\n",
    "        \n",
    "        return spa, wayuu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c8a1e6-2665-497a-b5ec-93445c5e1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy_model(model_name, tokenizer_name, src_lang, tgt_lang):\n",
    "\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, src_lang=src_lang)#, tgt_lang=tgt_lang)\n",
    "    tokenizer.add_tokens(AddedToken(tgt_lang, normalized=False, special=True))\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae8e28ed-41a3-4729-a839-56d7a8559069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rewards_translation(generations, correct_translations):\n",
    "\n",
    "    bleu = sacrebleu.BLEU(effective_order = True)\n",
    "    def get_bleu_score(sample, correct_translation):\n",
    "        # Compute bleu score for each sample. \n",
    "        # Bleu score normalized to [0, 1]\n",
    "        return bleu.sentence_score(sample, \n",
    "                                   [correct_translation]\n",
    "                                   ).score\n",
    "\n",
    "    answer_bleu_scores = [\n",
    "        get_bleu_score(sample, translation)\n",
    "        for sample, translation in zip(generations, correct_translations)\n",
    "    ]\n",
    "    \n",
    "    return answer_bleu_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d15ef54-217a-4eba-8b0d-0b8867b689cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_completion(model, tokenizer, prompts: list, return_ids=False, **kwargs):\n",
    "    default_sampling_args = {\n",
    "        'do_sample': True, # FIXME not enough memory in local\n",
    "        'max_new_tokens': 512,\n",
    "        'temperature': 0.8,\n",
    "        'top_p': 0.95, # FIXME not enough memory in local\n",
    "    }\n",
    "    default_sampling_args.update(kwargs)\n",
    "\n",
    "    model_inputs = tokenizer(prompts, padding='longest', padding_side='left', \\\n",
    "        return_tensors=\"pt\").to(model.device) # No VLLM\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        inputs=model_inputs.input_ids,\n",
    "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(\"way_Latn\"), # FIXME convert to param\n",
    "        **default_sampling_args\n",
    "    ) # Generation no VLLM\n",
    "\n",
    "    if return_ids:\n",
    "        generation_ids = [model_inputs.input_ids.tolist()[0] + list(output) for output in outputs.tolist()]  # Diferent tokenizer model.inputs\n",
    "        # padding the generation_ids to the max length\n",
    "        max_length = max([len(ids) for ids in generation_ids])\n",
    "        generation_ids = [ids + [tokenizer.pad_token_id]*(max_length-len(ids)) for ids in generation_ids]\n",
    "        generation_ids = torch.tensor(generation_ids)\n",
    "        return generation_ids, len(model_inputs.input_ids[0])\n",
    "\n",
    "    completions = tokenizer.batch_decode(outputs, skip_special_tokens=True) # No text in outputs had to tokenize decode\n",
    "    return completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87988450-ec73-4ff6-8849-d9d67ae9c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, dataloader, temperature, top_p, max_new_tokens):\n",
    "    prompts = []\n",
    "    golds = []\n",
    "    generations = []\n",
    "    bleu_scores = []\n",
    "    for inputs, targets in tqdm(dataloader):\n",
    "        generation = generate_batch_completion(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            inputs,\n",
    "            return_ids=False,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            max_new_tokens=max_new_tokens\n",
    "        )\n",
    "        bleu_score = get_rewards_translation(generation, targets)\n",
    "        golds.extend(targets)\n",
    "        prompts.extend(inputs)\n",
    "        generations.extend(generation)\n",
    "        bleu_scores.extend(bleu_score)\n",
    "    avg_bleu_score = sum(bleu_scores)/len(bleu_scores)\n",
    "    df_results = pd.DataFrame({\n",
    "        \"input\": prompts,\n",
    "        \"target\": golds,\n",
    "        \"generation\": generations,\n",
    "        \"scores\": bleu_scores\n",
    "    })\n",
    "    df_avg_bleu_score = pd.DataFrame({\"avg_bleu_score\": [avg_bleu_score]})\n",
    "    return df_results, df_avg_bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635351c-a05c-452c-923a-2b32cc24ffc1",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7f523-95e9-4c3e-878b-3e80196c1800",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8d31503-9d7c-44f3-a5c6-d421b7864435",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(SPANISH_VAL_FILE, WAYUU_VAL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61d33b0e-1757-4a1d-9770-a2c604b3f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225a111d-d88c-41ad-b395-7bfd39764c1a",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471d1eb9-3a88-4557-973d-ed83f13f9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = get_policy_model(MODEL_PATH, TOKENIZER_PATH, SRC_LANG, TGT_LANG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a358e1f-cfae-4c10-9caa-4332d6cee4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 6656)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader), 104*BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad324ae-fe99-4998-b0ac-426250bf1797",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bf83c9b-7386-4a40-b721-131ff2637ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████████                                                                                                                                           | 19/104 [02:14<08:46,  6.20s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1566 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 104/104 [18:42<00:00, 10.79s/it]\n"
     ]
    }
   ],
   "source": [
    "df_evaluation, df_avg_bleu_score = evaluate_model(model, tokenizer, dataloader, TEMPERATURE, TOP_P, MAX_NEW_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f260c496-aa1f-4775-8614-5e99e6099834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_bleu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.031024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_bleu_score\n",
       "0        8.031024"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fca4d31-d5c4-4120-9e6b-0224565bc665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>generation</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>se me empezaron a quitar las ganas de fumar</td>\n",
       "      <td>nnojoluitpa suchuntaain taa'in akamüjaa</td>\n",
       "      <td>müsüjese'e nnojoluinjatüin kapüleein akumajaa ...</td>\n",
       "      <td>1.379446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>como deberiamos ver la ley de jehova sobre la ...</td>\n",
       "      <td>jamüsü kojutüinjatka wamüin tü ishakat ma'aka ...</td>\n",
       "      <td>süpüla watüjaain saa'u jamüinjatüin sukumajia ...</td>\n",
       "      <td>3.300809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Con él va Onésimo, paisano de ustedes, no meno...</td>\n",
       "      <td>Chi o'uneechikai nümaa Tíquico, nia wane juwal...</td>\n",
       "      <td>Otta Tíquico, aishije'echi ma'i pia nüpüla. Ot...</td>\n",
       "      <td>5.352302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pero noemi estaba decidida a llegar a israel</td>\n",
       "      <td>ayatapaja'a noemi o'unüin israelmüin</td>\n",
       "      <td>o'unüsü shia israelmüin süka süntüinjatüin sün...</td>\n",
       "      <td>1.241494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>me sentia culpable por no poderles dar a mis h...</td>\n",
       "      <td>anuujese'e sünüiki janet shapaasü ma'in taa'in...</td>\n",
       "      <td>talatirüin toulia tü tamakat namüin na tepichi...</td>\n",
       "      <td>1.727224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>una cualidad cristiana mas valiosa que los dia...</td>\n",
       "      <td>tü akuwa'ipaa kojutüleekat suuliale'eya wanee ...</td>\n",
       "      <td>tü palajatkat shiyaawase eejatüin sukuwa'ipa j...</td>\n",
       "      <td>4.196115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>con este tratado denunciaron sin temor a la cr...</td>\n",
       "      <td>jee aküjünüsü tü shiimainkat nachiki na anouja...</td>\n",
       "      <td>otta tü karalouktakat la historia historica de...</td>\n",
       "      <td>4.266332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>los enemigos de dios llevan dos mil a os hacie...</td>\n",
       "      <td>so'u yaajachin jesuu yaa mmapa'a nachajaain ma...</td>\n",
       "      <td>kakaliashaatasü ma'in naa'in na nü'ünüükana ma...</td>\n",
       "      <td>13.973537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>con razon jesucristo pregunto quien de ustedes...</td>\n",
       "      <td>shiimainya ma'in tü nümakat jesuu wanaa sümaa ...</td>\n",
       "      <td>wanaa sümaa naapüin je'waa tü kataakalü o'u sü...</td>\n",
       "      <td>12.049515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mi huerta</td>\n",
       "      <td>ta apainse</td>\n",
       "      <td>müsia tü eekai anain süpülajatü tü eekai anain...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0        se me empezaron a quitar las ganas de fumar   \n",
       "1  como deberiamos ver la ley de jehova sobre la ...   \n",
       "2  Con él va Onésimo, paisano de ustedes, no meno...   \n",
       "3       pero noemi estaba decidida a llegar a israel   \n",
       "4  me sentia culpable por no poderles dar a mis h...   \n",
       "5  una cualidad cristiana mas valiosa que los dia...   \n",
       "6  con este tratado denunciaron sin temor a la cr...   \n",
       "7  los enemigos de dios llevan dos mil a os hacie...   \n",
       "8  con razon jesucristo pregunto quien de ustedes...   \n",
       "9                                          mi huerta   \n",
       "\n",
       "                                              target  \\\n",
       "0            nnojoluitpa suchuntaain taa'in akamüjaa   \n",
       "1  jamüsü kojutüinjatka wamüin tü ishakat ma'aka ...   \n",
       "2  Chi o'uneechikai nümaa Tíquico, nia wane juwal...   \n",
       "3               ayatapaja'a noemi o'unüin israelmüin   \n",
       "4  anuujese'e sünüiki janet shapaasü ma'in taa'in...   \n",
       "5  tü akuwa'ipaa kojutüleekat suuliale'eya wanee ...   \n",
       "6  jee aküjünüsü tü shiimainkat nachiki na anouja...   \n",
       "7  so'u yaajachin jesuu yaa mmapa'a nachajaain ma...   \n",
       "8  shiimainya ma'in tü nümakat jesuu wanaa sümaa ...   \n",
       "9                                         ta apainse   \n",
       "\n",
       "                                          generation     scores  \n",
       "0  müsüjese'e nnojoluinjatüin kapüleein akumajaa ...   1.379446  \n",
       "1  süpüla watüjaain saa'u jamüinjatüin sukumajia ...   3.300809  \n",
       "2  Otta Tíquico, aishije'echi ma'i pia nüpüla. Ot...   5.352302  \n",
       "3  o'unüsü shia israelmüin süka süntüinjatüin sün...   1.241494  \n",
       "4  talatirüin toulia tü tamakat namüin na tepichi...   1.727224  \n",
       "5  tü palajatkat shiyaawase eejatüin sukuwa'ipa j...   4.196115  \n",
       "6  otta tü karalouktakat la historia historica de...   4.266332  \n",
       "7  kakaliashaatasü ma'in naa'in na nü'ünüükana ma...  13.973537  \n",
       "8  wanaa sümaa naapüin je'waa tü kataakalü o'u sü...  12.049515  \n",
       "9  müsia tü eekai anain süpülajatü tü eekai anain...   0.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f376b8a4-2555-4e70-8aa5-44fbf085a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation.to_csv(f\"{EVALUATION_PATH}/bleu_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42bc2dbc-2528-4288-a05f-535c67118d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_bleu_score.to_csv(f\"{EVALUATION_PATH}/avg_bleu_score.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
